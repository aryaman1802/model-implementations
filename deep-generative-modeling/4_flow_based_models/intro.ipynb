{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpful resource:\n",
    "- [Lilian Weng's blog on Flow-based deep generative models](https://lilianweng.github.io/posts/2018-10-13-flow-models/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Why Do We Need Flow‑Based Models?**\n",
    "\n",
    "Imagine you have a simple \"source\" distribution (like a basic Gaussian) and you want to \"sculpt\" it into a much more complex shape to match real data (eg: the distribution of natural images). Flow‑based models achieve this by \"flowing\" the simple distribution through a series of invertible transformations. Think of it like molding clay: you start with a basic block and then apply a series of well‑designed moves until you get the shape you want.\n",
    "\n",
    "Key Advantages Compared to Other Deep Generative Models:\n",
    "\n",
    "- **Exact Likelihood Computation:** Unlike GANs (which only provide implicit density estimates) and some types of VAEs (which use approximations), flow‑based models let you compute the exact probability density of any given data point. This makes training and evaluation more straightforward.\n",
    "- **Efficient Sampling and Inversion:** Because the transformations are invertible, you can easily switch between the latent (simple) space and the data (complex) space. This is useful for both generating new data and for tasks like density estimation.\n",
    "- **Interpretability and Flexibility:** Each step in the model (each \"flow\") can be examined and understood, making it easier to see how the model transforms data step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Some jargon**\n",
    "\n",
    "- **Transformation** is a function that maps data from one space to another. In flow‑based models, transformations are invertible, meaning after you've transformed the data, you can still go back to the original space.\n",
    "- **Density estimation** is the problem of reconstructing the probability density function using a set of given data points.\n",
    "- In probability theory, a **probability density function (PDF)**, **density function**, or **density**, all mean the same thing: a function that describes the probability of a random variable taking on a particular value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Flows for Continuous Random Variables**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Big Picture**\n",
    "\n",
    "Think of a flow as a sequence of \"waterfalls\" that progressively reshape a simple stream (eg: a Gaussian distribution) into a complex river (the data distribution). Each waterfall is an invertible transformation that's carefully designed so that you can \"read back\" the exact change made to the probability density.\n",
    "\n",
    "Below is an in‐depth, step‐by‐step explanation of flow‑based models—starting with continuous random variables. I’ll begin with an intuitive introduction, build a clear roadmap of concepts, and then dive into the technical details. At the end of this section, I’ll pause to ask if you have any doubts before moving on to flows for discrete random variables.\n",
    "\n",
    "**The Change-of-Variables Principle:**  \n",
    "At the heart of flow‑based models is the change-of-variables formula from probability. If you have a random variable $\\mathbf{z}$ with a known density $p_{\\mathbf{z}}(\\mathbf{z})$ and you transform it using an invertible function $f$ such that\n",
    "\n",
    "$$\\mathbf{x} = f(\\mathbf{z})$$\n",
    "\n",
    "then the density $p_{\\mathbf{x}}(\\mathbf{x})$ is given by:\n",
    "\n",
    "$$p_{\\mathbf{x}}(\\mathbf{x}) = p_{\\mathbf{z}}(f^{-1}(\\mathbf{x})) \\left| \\det \\left( \\frac{\\partial f^{-1}(\\mathbf{x})}{\\partial \\mathbf{x}} \\right) \\right|$$\n",
    "\n",
    "This formula ensures that probability mass is conserved through the transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Deep Dive**\n",
    "\n",
    "The above just provided you with an intuition of how flow-based models work. Now, let's dive into the details.\n",
    "\n",
    "We start with the goal of transforming a simple probability distribution into a more complex one using an invertible function. The mathematical backbone is the **change‑of‑variables formula**. Let's systematically break it down.\n",
    "\n",
    "### **Probability Conservation**\n",
    "\n",
    "**Concept:**  \n",
    "Imagine you have a bucket of water. No matter how you pour or reshape the water (without spilling any), the total amount remains constant. In probability, this \"water\" is the probability mass.\n",
    "\n",
    "- **Mathematically:**  \n",
    "  If you have a random variable $z$ with density $p_z(z)$, then for any region $A$ in the space, the probability that $z$ falls in $A$ is:\n",
    "  \n",
    "  $$P(z \\in A) = \\int_A p_z(z) \\, dz$$\n",
    "  \n",
    "  Now, if we transform $ z $ via an invertible function $ f $ such that\n",
    "  \n",
    "  $$x = f(z)$$\n",
    "  then every set $ A $ in the $ z $-space corresponds to a set $ f(A) $ in the $ x $-space. Since no probability is lost:\n",
    "  $$\\int_A p_z(z) \\, dz = \\int_{f(A)} p_x(x) \\, dx$$\n",
    "\n",
    "### **Change of Variables in Integrals**\n",
    "\n",
    "**Why change variables?**  \n",
    "When we change the variable of integration (from $z$ to $x$), the size of a small \"chunk\" of space (an infinitesimal volume) changes. In calculus, this is handled by the **Jacobian determinant**.\n",
    "\n",
    "- **Substitution:**  \n",
    "  Given $x = f(z)$, a small change $ dz $ in $ z $ corresponds to a change $ dx $ in $ x $. The relationship is:\n",
    "  \n",
    "  $$dx = \\Bigl|\\det\\left(\\frac{\\partial f(z)}{\\partial z}\\right)\\Bigr| dz$$\n",
    "  where $\\frac{\\partial f(z)}{\\partial z}$ is the Jacobian matrix of partial derivatives and the determinant tells you how much a small volume element is scaled by $f$.\n",
    "\n",
    "### **Step-by-Step Derivation**\n",
    "\n",
    "Now, let's go through the derivation:\n",
    "\n",
    "1. **Start with Probability Conservation:**  \n",
    "   For any measurable set $A$,\n",
    "   $$\\int_A p_z(z) \\, dz = \\int_{f(A)} p_x(x) \\, dx$$\n",
    "   This equation means the probability mass in $A$ under $z$ is exactly the mass in $f(A)$ under $x$.\n",
    "\n",
    "2. **Apply Change of Variables:**  \n",
    "   Substitute $x = f(z)$ in the right integral. Changing variables gives:\n",
    "   \n",
    "   $$dx = \\Bigl|\\det\\left(\\frac{\\partial f(z)}{\\partial z}\\right)\\Bigr| dz$$\n",
    "   \n",
    "   So the integral becomes:\n",
    "\n",
    "   $$\\int_A p_x(f(z)) \\Bigl|\\det\\left(\\frac{\\partial f(z)}{\\partial z}\\right)\\Bigr| dz$$\n",
    "\n",
    "3. **Set the Integrands Equal:**  \n",
    "   Because the above equality holds for every set $A$, the integrands themselves must be equal almost everywhere. Hence,\n",
    "   \n",
    "   $$p_x(f(z)) \\Bigl|\\det\\left(\\frac{\\partial f(z)}{\\partial z}\\right)\\Bigr| = p_z(z)$$\n",
    "\n",
    "4. **Solve for $p_x(x)$:**  \n",
    "   \n",
    "   Replace $z$ with $f^{-1}(x)$ (since $f$ is invertible):\n",
    "   \n",
    "   $$p_x(x) = p_z(f^{-1}(x)) \\Bigl|\\det\\left(\\frac{\\partial f^{-1}(x)}{\\partial x}\\right)\\Bigr|$$\n",
    "\n",
    "   This is the **change‑of‑variables formula** that tells us how to compute the density $p_x(x)$ after applying the invertible transformation $f$.\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "- **Probability Conservation:**  \n",
    "  It means that if you \"reshape\" the distribution by a transformation, the total probability (mass) stays the same.\n",
    "\n",
    "- **Change of Variables in Integrals:**  \n",
    "  In integration, when you switch from one variable to another, you must adjust the \"size\" of the differential element by the Jacobian determinant. This step is essential to ensure that areas (or volumes) are properly scaled.\n",
    "\n",
    "- **Jacobian Determinant:**  \n",
    "  For a function $f:\\mathbb{R}^n \\to \\mathbb{R}^n$, the Jacobian matrix $J_f(z)$ is a square matrix of first derivatives. Its determinant, $\\det(J_f(z))$, tells us by what factor the transformation scales a small volume around $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above concepts in mind, we can implement the RealNVP model, a popular flow-based model for continuous random variables. You can check it out in the [`realnvp.ipynb`](https://github.com/aryaman1802/model-implementations/blob/main/generative-deep-learning/4_flow_based_models/realnvp.ipynb) notebook in this directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Flows for Discrete Random Variables**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
