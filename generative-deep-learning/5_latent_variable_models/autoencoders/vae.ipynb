{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder (VAE)\n",
    "\n",
    "Paper: [Auto-Encoding Variational Bayes](https://arxiv.org/pdf/1312.6114)\n",
    "\n",
    "Helpful resources:\n",
    "- [Datacamp's tutorial on VAE](https://www.datacamp.com/tutorial/variational-autoencoders)\n",
    "- [CodeEmporium's video on VAE](https://youtu.be/fcvYpzHmhvA?si=WBQ9X6yVhKPOVagA)\n",
    "- [Stanford's Deep Generative Models playlist](https://youtube.com/playlist?list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8&si=N_TpTe1bPIhte-t8)\n",
    "- ExplainingAI's videos on VAE:\n",
    "    - [Understanding VAE](https://youtu.be/1RPdu_5FCfk?si=ku_-AMmJI991t0To)\n",
    "    - [Implementing VAE](https://youtu.be/pEsC0Vcjc7c?si=u3mBvhTaJ77a-mnP)\n",
    "- [AI Summer's blog on VAE](https://theaisummer.com/latent-variable-models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Imports done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Problems with a simple autoencoder**\n",
    "\n",
    "- Sampled images might not be valid (or realistic):\n",
    "    - Simple autoencoders will try to push away the training points in the latent space as far apart as possible. This is because the loss function of the autoencoder is based on the reconstruction error, and the model will try to minimize this error by pushing the points away from each other.\n",
    "    - When we sample a point from the latent space, it might not be a valid point, and the decoder might not be able to generate a realistic image from it.\n",
    "- New variations of the data are not possible:\n",
    "    - Since we don't know the distribution of the data in the latent space, we can't sample new points from it. We can only sample the points that are present in the training set.\n",
    "    - So, a simple autoencoder memorizes the *mapping* of the training data to the latent space, but it doesn't learn the *distribution* of the data in the latent space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **How does a Variational Autoencoder (VAE) solve these problems?**\n",
    "\n",
    "- **VAE learns the distribution of the data in the latent space**:\n",
    "    - VAE assumes that the data in the latent space follows a Gaussian distribution. This assumption allows us to sample new points from the latent space.\n",
    "- **VAE generates new data points**:\n",
    "    - Since we know the distribution of the data in the latent space, we can sample new points from it and generate new data points using the decoder.\n",
    "- **VAE generates realistic images**:\n",
    "    - The decoder of the VAE is trained to generate realistic images from the points sampled from the latent space. This is because the loss function of the VAE is based on the reconstruction error and the KL divergence between the distribution of the data in the latent space and the Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
