{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Deep Convolutional Generative Adversarial Network (DCGAN)\n","\n","Paper: [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/pdf/1511.06434v2)\n","\n","Helpful Resources:\n","- [Aladdin Persson's playlist on GANs](https://youtube.com/playlist?list=PLhhyoLH6IjfwIp8bZnzX8QR30TRcHO8Va&si=8ooImkbbXhCUC1xB)\n","- [GANs specialization on Coursera](https://www.coursera.org/specializations/generative-adversarial-networks-gans)\n","- [Stanford's Deep Generative Models playlist](https://youtube.com/playlist?list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8&si=N_TpTe1bPIhte-t8)\n","- [AssemblyAI's GAN tutorial](https://youtu.be/_pIMdDWK5sc?si=Mtx2oWh1ZO9tqWYg)"]},{"cell_type":"markdown","metadata":{},"source":["This notebook just includes the implementation of the DCGAN model and its training loop. The results are not shown here.\n","\n","Feel free to check the results on my Kaggle notebook: https://www.kaggle.com/code/aryamanbansal/dcgan"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-12-04T09:08:13.536264Z","iopub.status.busy":"2024-12-04T09:08:13.535999Z","iopub.status.idle":"2024-12-04T09:08:17.534075Z","shell.execute_reply":"2024-12-04T09:08:17.533224Z","shell.execute_reply.started":"2024-12-04T09:08:13.536237Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Imports done!\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import MNIST\n","from torchvision.utils import make_grid\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","\n","torch.manual_seed(0)\n","\n","print(\"Imports done!\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-12-04T09:08:21.550352Z","iopub.status.busy":"2024-12-04T09:08:21.549466Z","iopub.status.idle":"2024-12-04T09:08:21.554809Z","shell.execute_reply":"2024-12-04T09:08:21.553988Z","shell.execute_reply.started":"2024-12-04T09:08:21.550317Z"},"trusted":true},"outputs":[],"source":["def plot_images(img_tensor, num_imgs=25, size=(1,28,28)):\n","    \"\"\"\n","    Given a tensor of images, number of images, and size per image, \n","    this function plots and prints the images in a uniform grid.\n","    \"\"\"\n","    img_unflat = img_tensor.detach().cpu().view(-1, *size)\n","    img_grid = make_grid(img_unflat[:num_imgs], nrow=5)\n","    plt.imshow(img_grid.permute(1,2,0).squeeze())\n","    plt.show()\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-12-04T09:08:22.012197Z","iopub.status.busy":"2024-12-04T09:08:22.011413Z","iopub.status.idle":"2024-12-04T09:08:22.016606Z","shell.execute_reply":"2024-12-04T09:08:22.015750Z","shell.execute_reply.started":"2024-12-04T09:08:22.012165Z"},"trusted":true},"outputs":[],"source":["def plot_results(results):\n","    \"\"\"\n","    results is dictionary with keys: \"gen_train_loss\", \"gen_test_loss\", \n","        \"disc_train_loss\", \"disc_test_loss\", \"gen_train_acc\", \"gen_test_acc\", \n","        \"disc_train_acc\", \"disc_test_acc\".\n","    This function plots the train and test losses and accuracies.\n","\n","    However, for now, we'll only plot the train losses for the generator and discriminator.\n","    \"\"\"\n","    plt.plot(results[\"gen_train_loss\"], label=\"Generator train loss\")\n","    plt.plot(results[\"disc_train_loss\"], label=\"Discriminator train loss\")\n","    plt.legend()\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","    "]},{"cell_type":"markdown","metadata":{},"source":["Quoting from the DCGAN paper:\n","\n","> Architecture guidelines for stable Deep Convolutional GANs:\n","> - Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator).\n","> - Use batchnorm in both the generator and the discriminator.\n","> - Remove fully connected hidden layers for deeper architectures.\n","> - Use ReLU activation in generator for all layers except for the output, which uses Tanh.\n","> - Use LeakyReLU activation in the discriminator for all layers."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-12-04T09:08:23.315538Z","iopub.status.busy":"2024-12-04T09:08:23.314674Z","iopub.status.idle":"2024-12-04T09:08:23.323005Z","shell.execute_reply":"2024-12-04T09:08:23.322103Z","shell.execute_reply.started":"2024-12-04T09:08:23.315502Z"},"trusted":true},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self, z_dim=10, img_channel=1, hidden_dim=64):\n","        \"\"\"\n","        Parameters:\n","        - z_dim: the dimension of the noise vector, a scalar\n","        - img_channel: the number of channels of the output image, a scalar\n","            (MNIST is grayscale, so default value is img_channel=1)\n","        - hidden_dim: the inner dimension, a scalar\n","        \"\"\"\n","        super(Generator, self).__init__()\n","        self.z_dim = z_dim\n","        self.gen = nn.Sequential(\n","            self.gen_block(z_dim, hidden_dim*4),\n","            self.gen_block(hidden_dim*4, hidden_dim*2, kernel_size=4, stride=1),\n","            self.gen_block(hidden_dim*2, hidden_dim),\n","            self.gen_block(hidden_dim, img_channel, kernel_size=4, final_layer=True)\n","        )\n","\n","    def gen_block(self, in_channel, out_channel, kernel_size=3, stride=2, \n","                  final_layer=False):\n","        \"\"\"\n","        Returns the layers of a generator block.\n","\n","        Parameters:\n","        - in_channel: the number of channels in the input, a scalar\n","        - out_channel: the number of channels in the output, a scalar\n","        - kernel_size: the size of the kernel, a scalar\n","        - stride: the stride of the kernel, a scalar\n","        - final_layer: a boolean, True if this is the final layer and False otherwise\n","        \"\"\"\n","        if not final_layer:\n","            return nn.Sequential(\n","                nn.ConvTranspose2d(in_channel, out_channel, \n","                                   kernel_size=kernel_size, stride=stride),\n","                nn.BatchNorm2d(out_channel),\n","                nn.ReLU(inplace=True)\n","            )\n","        else:\n","            return nn.Sequential(\n","                nn.ConvTranspose2d(in_channel, out_channel, \n","                                   kernel_size=kernel_size, stride=stride),\n","                nn.Tanh()\n","            )\n","        \n","    def forward(self, noise):\n","        \"\"\"\n","        Given a noise tensor, returns the generated image.\n","        \"\"\"\n","        x = noise.view(len(noise), self.z_dim, 1, 1)\n","        return self.gen(x)\n","    "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-12-04T09:08:23.832274Z","iopub.status.busy":"2024-12-04T09:08:23.831987Z","iopub.status.idle":"2024-12-04T09:08:23.839313Z","shell.execute_reply":"2024-12-04T09:08:23.838480Z","shell.execute_reply.started":"2024-12-04T09:08:23.832247Z"},"trusted":true},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, img_channel=1, hidden_dim=16):\n","        \"\"\"\n","        Parameters:\n","        - img_channel: the number of channels of the input image, a scalar\n","            (MNIST is grayscale, so default value is img_channel=1)\n","        - hidden_dim: the inner dimension, a scalar\n","        \"\"\"\n","        super(Discriminator, self).__init__()\n","        self.disc = nn.Sequential(\n","            self.disc_block(img_channel, hidden_dim),\n","            self.disc_block(hidden_dim, hidden_dim*2),\n","            self.disc_block(hidden_dim*2, 1, final_layer=True)\n","        )\n","\n","    def disc_block(self, in_channel, out_channel, kernel_size=4, stride=2,\n","                   final_layer=False):\n","          \"\"\"\n","          Returns the layers of a discriminator block.\n","    \n","          Parameters:\n","          - in_channel: the number of channels in the input, a scalar\n","          - out_channel: the number of channels in the output, a scalar\n","          - kernel_size: the size of the kernel, a scalar\n","          - stride: the stride of the kernel, a scalar\n","          - final_layer: a boolean, True if this is the final layer and False otherwise\n","          \"\"\"\n","          if not final_layer:\n","                return nn.Sequential(\n","                 nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, \n","                           stride=stride),\n","                 nn.BatchNorm2d(out_channel),\n","                 nn.LeakyReLU(0.2)\n","                )\n","          else:\n","                return nn.Sequential(\n","                 nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, \n","                           stride=stride),\n","                nn.Sigmoid()\n","                )\n","\n","    def forward(self, image):\n","        \"\"\"\n","        Given an image tensor, returns a 1-dimension tensor \n","        representing fake/real.\n","        Parameters:\n","            image: a flattened image tensor\n","        \"\"\"\n","        disc_pred = self.disc(image)\n","        return disc_pred.view(len(disc_pred), -1)\n"]},{"cell_type":"markdown","metadata":{},"source":["Up till now, we observed changes in the architectures of the generator and the discriminator.\n","\n","Let's now move onto the training loop and the loss functions."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-12-04T09:08:24.918709Z","iopub.status.busy":"2024-12-04T09:08:24.918404Z","iopub.status.idle":"2024-12-04T09:08:24.985635Z","shell.execute_reply":"2024-12-04T09:08:24.984491Z","shell.execute_reply.started":"2024-12-04T09:08:24.918681Z"},"trusted":true},"outputs":[],"source":["# Hyperparameters\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","lr = 2e-4           \n","z_dim = 64          # latent noise dimension\n","img_dim = 1         # 1 means grayscale image\n","batch_size = 128\n","num_epochs = 50\n","display_step = 500   # after how many steps to display loss\n","\n","# These parameters control the optimizer's momentum:\n","# https://distill.pub/2017/momentum/\n","beta_1 = 0.5 \n","beta_2 = 0.999"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-12-04T09:08:25.461400Z","iopub.status.busy":"2024-12-04T09:08:25.461100Z","iopub.status.idle":"2024-12-04T09:08:38.538729Z","shell.execute_reply":"2024-12-04T09:08:38.537806Z","shell.execute_reply.started":"2024-12-04T09:08:25.461371Z"},"trusted":true},"outputs":[],"source":["transformations = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","train_dataset = MNIST(root=\"dataset/\", transform=transformations, download=True, train=True)\n","test_dataset = MNIST(root=\"dataset/\", transform=transformations, download=True, train=False)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-12-04T09:08:38.541107Z","iopub.status.busy":"2024-12-04T09:08:38.540324Z","iopub.status.idle":"2024-12-04T09:08:38.626137Z","shell.execute_reply":"2024-12-04T09:08:38.625279Z","shell.execute_reply.started":"2024-12-04T09:08:38.541066Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2\n","torch.Size([128, 1, 28, 28]) torch.Size([128])\n"]}],"source":["def fn():\n","    for item in train_loader:\n","        print(len(item))\n","        print(item[0].shape, item[1].shape)\n","        break\n","\n","fn()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-12-04T09:08:42.170729Z","iopub.status.busy":"2024-12-04T09:08:42.170048Z","iopub.status.idle":"2024-12-04T09:08:42.338258Z","shell.execute_reply":"2024-12-04T09:08:42.337560Z","shell.execute_reply.started":"2024-12-04T09:08:42.170696Z"},"trusted":true},"outputs":[],"source":["disc = Discriminator(img_dim).to(device)\n","gen = Generator(z_dim, img_dim).to(device)\n","\n","# fixed_noise is the latent noise vector\n","# torch.randn generates random numbers from a normal distribution\n","fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n","\n","# separate optimizers for generator and discriminator\n","optim_disc = optim.Adam(disc.parameters(), lr=lr, betas=(beta_1, beta_2))\n","optim_gen = optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n","\n","criterion = nn.BCELoss()  # binary cross entropy loss"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-12-04T09:08:42.580713Z","iopub.status.busy":"2024-12-04T09:08:42.580438Z","iopub.status.idle":"2024-12-04T09:08:42.616320Z","shell.execute_reply":"2024-12-04T09:08:42.615706Z","shell.execute_reply.started":"2024-12-04T09:08:42.580687Z"},"trusted":true},"outputs":[],"source":["# You initialize the weights to the normal distribution\n","# with mean 0 and standard deviation 0.02\n","def weights_init(m):\n","    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n","        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n","    if isinstance(m, nn.BatchNorm2d):\n","        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n","        torch.nn.init.constant_(m.bias, 0)\n","\n","gen = gen.apply(weights_init)\n","disc = disc.apply(weights_init)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-12-04T09:08:43.535487Z","iopub.status.busy":"2024-12-04T09:08:43.534585Z","iopub.status.idle":"2024-12-04T09:08:43.541311Z","shell.execute_reply":"2024-12-04T09:08:43.540427Z","shell.execute_reply.started":"2024-12-04T09:08:43.535455Z"},"trusted":true},"outputs":[],"source":["def get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):\n","    \"\"\"\n","    Returns the loss of the discriminator.\n","    Parameters:\n","        - gen: the generator model, which returns an image given \n","               z-dimensional noise\n","        - disc: the discriminator model, which returns a single-dimensional \n","                prediction of real/fake\n","        - criterion: the loss function, which should be used to compare \n","                     the discriminator's predictions to the ground truth \n","                     reality of the images (e.g. fake = 0, real = 1)\n","        - real: a batch of real images\n","        - num_images: the number of images the generator should produce, \n","                      which is also the length of the real images\n","        - z_dim: the dimension of the noise vector, a scalar\n","        - device: the device type (eg: cuda or cpu)\n","    Returns:\n","        disc_loss: a torch scalar loss value for the current batch\n","\n","    The following is the mathematical formula for the discriminator loss:\n","        max(log(D(x)) + log(1 - D(G(z))))\n","    \"\"\"\n","    \n","    # 1) Create a noise vector and generate a batch (ie, num_images) of fake images.\n","    noise_vector = torch.randn(num_images, z_dim).to(device)  # z\n","    fake_images = gen(noise_vector)                           # G(z)\n","\n","    # 2) Get the discriminator's prediction of the fake image \n","    #    and calculate the loss. Don't forget to detach the generator!\n","    #    (Remember the loss function you set earlier -- criterion. You need a \n","    #    'ground truth' tensor in order to calculate the loss. \n","    #    For example, a ground truth tensor for a fake image is all zeros.)\n","    disc_fake_preds = disc(fake_images.detach())                   # D(G(z))\n","    disc_fake_loss = criterion(disc_fake_preds, \n","                               torch.zeros_like(disc_fake_preds))  # log(1 - D(G(z)))\n","    \n","    # 3) Get the discriminator's prediction of the real image and calculate the loss.\n","    disc_real_preds = disc(real)                                   # D(x)\n","    disc_real_loss = criterion(disc_real_preds, \n","                               torch.ones_like(disc_real_preds))   # log(D(x))\n","\n","    # 4) Calculate the discriminator's loss by averaging the real and fake loss\n","    #    and set it to disc_loss.\n","    disc_loss = (disc_fake_loss + disc_real_loss) / 2\n","    \n","    return disc_loss\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-12-04T09:08:43.974631Z","iopub.status.busy":"2024-12-04T09:08:43.974310Z","iopub.status.idle":"2024-12-04T09:08:43.980026Z","shell.execute_reply":"2024-12-04T09:08:43.979117Z","shell.execute_reply.started":"2024-12-04T09:08:43.974602Z"},"trusted":true},"outputs":[],"source":["def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n","    \"\"\"\n","    Returns the loss of the generator.\n","    Parameters:\n","        - gen: the generator model, which returns an image given \n","               z-dimensional noise\n","        - disc: the discriminator model, which returns a single-dimensional \n","                prediction of real/fake\n","        - criterion: the loss function, which should be used to compare \n","                     the discriminator's predictions to the ground truth \n","                     reality of the images (e.g. fake = 0, real = 1)\n","        - num_images: the number of images the generator should produce, \n","                      which is also the length of the real images\n","        - z_dim: the dimension of the noise vector, a scalar\n","        - device: the device type (eg: cuda or cpu)\n","    Returns:\n","        gen_loss: a torch scalar loss value for the current batch\n","\n","    The following is the mathematical formula for the generator loss:\n","        max(log(D(G(z))))\n","    \"\"\"\n","\n","    # 1) Create noise vectors and generate a batch of fake images.\n","    noise_vector = torch.randn(num_images, z_dim).to(device)  # z\n","    fake_images = gen(noise_vector)                           # G(z)\n","\n","    # 2) Get the discriminator's prediction of the fake image.\n","    disc_fake_preds = disc(fake_images)                       # D(G(z))\n","\n","    # 3) Calculate the generator's loss. Remember the generator wants\n","    #    the discriminator to think that its fake images are real\n","    gen_loss = criterion(disc_fake_preds, \n","                         torch.ones_like(disc_fake_preds))    # log(D(G(z)))\n","\n","    return gen_loss\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-12-04T09:08:44.559694Z","iopub.status.busy":"2024-12-04T09:08:44.559113Z","iopub.status.idle":"2024-12-04T09:20:30.918158Z","shell.execute_reply":"2024-12-04T09:20:30.917283Z","shell.execute_reply.started":"2024-12-04T09:08:44.559663Z"},"trusted":true},"outputs":[],"source":["current_step = 0\n","mean_generator_loss = 0\n","mean_discriminator_loss = 0\n","results = {\n","    \"gen_train_loss\": [],\n","    \"disc_train_loss\": [],\n","}\n","\n","for epoch in tqdm(range(num_epochs)):\n","    \n","    # we iterate over the training dataloader\n","    # we only need the images, and not the labels\n","    for real_img, _ in train_loader:\n","        \n","        curr_batch_size = len(real_img)\n","        # No need to flatten the batch of real images,\n","        # as we're using DCGAN which uses convolutional layers\n","        real_img = real_img.to(device)\n","\n","        # Update discriminator (Notice that we first train the discriminator)\n","        # Zero out the gradients before backpropagation\n","        optim_disc.zero_grad()\n","        # Calculate the discriminator loss\n","        disc_loss = get_disc_loss(gen, disc, criterion, real_img, curr_batch_size, z_dim, device)\n","        # Update gradients\n","        disc_loss.backward(retain_graph=True)  # we need to re-use the gradients for the generator\n","        # Update optimizer\n","        optim_disc.step()\n","\n","        # Update generator\n","        # Zero out the gradients before backpropagation\n","        optim_gen.zero_grad()\n","        # Calculate the generator loss\n","        gen_loss = get_gen_loss(gen, disc, criterion, curr_batch_size, z_dim, device)\n","        # Update gradients\n","        gen_loss.backward()   # we have re-used the gradients for the generator, so no need to save the gradients\n","        # Update optimizer\n","        optim_gen.step()\n","\n","        # Keep track of the average discriminator loss\n","        mean_discriminator_loss += disc_loss.item()\n","        # Keep track of the average generator loss\n","        mean_generator_loss += gen_loss.item()\n","\n","        # Visualization code\n","        if current_step % display_step == 0 and current_step > 0:\n","            mean_discriminator_loss = mean_discriminator_loss / display_step\n","            mean_generator_loss = mean_generator_loss / display_step\n","            results[\"gen_train_loss\"].append(mean_generator_loss)\n","            results[\"disc_train_loss\"].append(mean_discriminator_loss)\n","            print(f\"Step {current_step}: Generator loss: {mean_generator_loss}, Discriminator loss: {mean_discriminator_loss}\")\n","            fake_noise = torch.randn(curr_batch_size, z_dim).to(device)\n","            fake_img = gen(fake_noise)\n","            plot_images(fake_img)\n","            plot_images(real_img)\n","            mean_generator_loss = 0\n","            mean_discriminator_loss = 0\n","        current_step += 1\n","        "]},{"cell_type":"markdown","metadata":{},"source":["**A note about image generation using DCGAN**\n","\n","During training, you see 2 grids of MNIST digits displayed after every epoch. The first one shows fake digits produced by the generator and the second one shows the real images. You might be tempted to think that the generator is trying to mimic the real images and is attempting to *copy* the real images. But this is not true. What is actually happening is that we feed a noise vector to the generator that causes it to generate the fake images. So, the digits displayed might be different as they're randomly being generated by the generator. \n","\n","Note: The type of GAN we're using is a very basic version of the different variants of GANs present today. It does not have the capability to generate an image given some prompt. At this stage, it can only generate random images, given some input noise vector."]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-12-04T09:20:30.919727Z","iopub.status.busy":"2024-12-04T09:20:30.919456Z","iopub.status.idle":"2024-12-04T09:20:31.138116Z","shell.execute_reply":"2024-12-04T09:20:31.137287Z","shell.execute_reply.started":"2024-12-04T09:20:30.919700Z"},"trusted":true},"outputs":[],"source":["plot_results(results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
