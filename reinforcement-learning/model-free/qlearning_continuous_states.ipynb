{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning (off-policy TD Control) for Continous State Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources used while writing this notebook:\n",
    "- [Nimish Sanghi's book on Deep RL](https://www.amazon.com/Deep-Reinforcement-Learning-Python-TensorFlow/dp/1484268083)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some info about the CartPole environment:\n",
    "\n",
    "A pole is attached to a cart which moves on a frictionless surface. The pole starts upright at the start of episode. The goal is to prevent the pole from falling by increasing or decreasing the velocity of the cart. \n",
    "\n",
    "Observation Space $\\; \\rightarrow \\; $ (Cart position, Cart velocity, Pole angle, Pole angular velocity):\n",
    "- x-position: from -4.8 to 4.8\n",
    "- x-velocity: from -$\\infty$ to $\\infty$\n",
    "- pole-angle: from $-24^{\\circ}$ (or $\\approx -0.418$ rad) to $24^{\\circ}$ (or $\\approx 0.418$ rad)\n",
    "- pole angular velocity: from -$\\infty$ to $\\infty$\n",
    "\n",
    "Action Space: The agent can either take action 0 or action 1, indicating the direction of the fixed force the cart is pushed with.\n",
    "- 0 $\\; \\rightarrow \\;$ Push cart to the left\n",
    "- 1 $\\; \\rightarrow \\;$ Push cart to the right\n",
    "\n",
    "Rewards: Since the goal is to keep the pole upright for as long as possible, by default, a reward of +1 is given for every step taken, including the termination step. The agent wants to maximize reward by keep pole balanced for longest time interval. The episode terminates once the pole angle is more than $12^{\\circ}$  in either direction or the cart position is beyond 2.4 from the center, i.e., either less than -2.4 or greater than 2.4. In addition, the episode ends when the agent is able to keep the pole upright for 500 steps continuously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_Learning:\n",
    "    \"\"\"Q-learning (off-policy TD control) algorithm.\"\"\"\n",
    "    def __init__(self, get_possible_actions, strategy, \n",
    "                 epsilon=1, alpha=1, gamma=1):\n",
    "        self._Q = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        self.get_possible_actions = get_possible_actions\n",
    "        self.epsilon = epsilon\n",
    "        self.strategy = strategy\n",
    "        self.alpha = alpha   # learning rate or step size\n",
    "        self.gamma = gamma   # discount factor\n",
    "\n",
    "\n",
    "    def _get_Q(self, state, action):\n",
    "        return self._Q[state][action]\n",
    "\n",
    "\n",
    "    def set_Q(self, state, action, value):\n",
    "        self._Q[state][action] = value\n",
    "\n",
    "\n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        This is the main update function for the Q-learning algorithm.\n",
    "        Note that this function only contains the update equations, \n",
    "        not the entire Q-learning algorithm.\n",
    "        \"\"\"\n",
    "        if not done:\n",
    "            best_next_action = self.max_action(next_state)\n",
    "            td_error = reward + \\\n",
    "                       self.gamma * self._get_Q(next_state, best_next_action) - \\\n",
    "                       self._get_Q(state, action)\n",
    "        else:\n",
    "            td_error = reward - self._get_Q(state, action)\n",
    "        q_value = self._get_Q(state, action) + self.alpha * td_error\n",
    "        self.set_Q(state, action, q_value)\n",
    "\n",
    "\n",
    "    def max_action(self, state):\n",
    "        \"\"\"\n",
    "        Return the best action for a given state, ie,\n",
    "        the action in the state-action pair that has the highest Q-value.\n",
    "        If there are multiple actions with the same Q-value,\n",
    "        return a random action from the set of best actions.\n",
    "        \"\"\"\n",
    "        actions = self.get_possible_actions(state)\n",
    "        best_action = []\n",
    "        best_q_value = float(\"-inf\")\n",
    "        for action in actions:\n",
    "            q_value = self._get_Q(state, action)\n",
    "            if q_value > best_q_value:\n",
    "                best_action = [action]\n",
    "                best_q_value = q_value\n",
    "            elif q_value == best_q_value:\n",
    "                best_action.append(action)\n",
    "        return np.random.choice(np.array(best_action))\n",
    "\n",
    "\n",
    "    def get_action(self, state):\n",
    "        \"\"\"\n",
    "        Choose an action based on the input strategy.\n",
    "        \"\"\"\n",
    "        return self.strategy(self.epsilon, self.get_possible_actions,\n",
    "                             state, self.max_action)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_strategy(epsilon, get_possible_actions, state, max_action):\n",
    "    \"\"\"\n",
    "    Epsilon-greedy strategy.\n",
    "\n",
    "    Choose a random number in the interval [0, 1) with a uniform \n",
    "    probability distribution. Use np.random.random() to do this.\n",
    "\n",
    "    If this random number is less than epsilon, return a random action.\n",
    "    Otherwise, return the best action for the given state.\n",
    "    \"\"\"\n",
    "    actions = get_possible_actions(state)\n",
    "    if len(actions) == 0:\n",
    "        return None\n",
    "    random_number = np.random.random()\n",
    "    if random_number < epsilon:\n",
    "        # exploration\n",
    "        return np.random.choice(actions)\n",
    "    else:\n",
    "        # exploitation\n",
    "        return max_action(state)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, size):\n",
    "        \"\"\"\n",
    "        :param size: maximum number of items in the buffer\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        self.buffer = []  # list to store the items\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        Add a new item to the buffer.\n",
    "        If the buffer is full, remove the oldest item.\n",
    "        \"\"\"\n",
    "        item = (state, action, reward, next_state, done)\n",
    "        self.buffer = self.buffer[-self.size:] + [item]\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"\n",
    "        Sample a batch of items from the buffer.\n",
    "        \"\"\"\n",
    "        idxs = np.random.choice(len(self.buffer), batch_size)\n",
    "        samples = [self.buffer[i] for i in idxs]\n",
    "        state, action, reward, next_state, done_flag = list(zip(*samples))\n",
    "        return state, action, reward, next_state, done_flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(env, agent, num_episodes=10_000, t_max=10_000, decay_rate=None,\n",
    "                replay_buffer=None, batch_size=16):\n",
    "    \"\"\"\n",
    "    This is a generic training function.\n",
    "\n",
    "    env: gymnasium environment\n",
    "    agent: Q_Learning object\n",
    "    num_episodes: (int) number of episodes to train the agent\n",
    "    t_max: (int) maximum number of steps per episode\n",
    "    decay_rate: (float) epsilon decay rate\n",
    "    replay_buffer: ReplayBuffer object\n",
    "    batch_size: (int) batch size for experience replay\n",
    "    \"\"\"\n",
    "    episode_rewards = []\n",
    "    for i in tqdm(range(num_episodes)):\n",
    "        G = 0\n",
    "        state, _ = env.reset()\n",
    "        for t in range(t_max):\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, trunc, _ = env.step(action)\n",
    "            flag = (done or trunc)\n",
    "            if replay_buffer is not None:\n",
    "                replay_buffer.add(state, action, reward, next_state, flag)\n",
    "                states, actions, rewards, next_states, done_flags = \\\n",
    "                    replay_buffer.sample(batch_size)\n",
    "                for i in range(batch_size):\n",
    "                    agent.update(states[i], actions[i], rewards[i],\n",
    "                                 next_states[i], done_flags[i])\n",
    "            else:\n",
    "                agent.update(state, action, reward, next_state, flag)\n",
    "            G += reward\n",
    "            if flag:\n",
    "                episode_rewards.append(G)\n",
    "                if decay_rate is not None:\n",
    "                    agent.epsilon = agent.epsilon * decay_rate\n",
    "                break\n",
    "            state = next_state\n",
    "    return np.array(episode_rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rewards(env_name, rewards, label):\n",
    "    plt.title(f\"Env: {env_name}  Mean Reward: {np.mean(rewards[-20:]):.1f}\")\n",
    "    plt.plot(rewards, label=label)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Observation Wrapper`: https://gymnasium.farama.org/api/wrappers/observation_wrappers/#gymnasium.ObservationWrapper.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import ObservationWrapper\n",
    "\n",
    "class Discretizer(ObservationWrapper):\n",
    "    \"\"\"\n",
    "    We will use ObservationWrapper class from gym to wrap our environment.\n",
    "    We need to implement observation() method which will receive the\n",
    "    original state values from underlying environment.\n",
    "    In observation() we will discretize the state values, which then\n",
    "    will be passed to outside world by env. \n",
    "    The agent will use these discrete state values to learn an \n",
    "    effective policy using Q-learning.\n",
    "    \"\"\"\n",
    "    def observation(self, state):\n",
    "        discrete_x_pos = round(state[0], 1)\n",
    "        discrete_x_vel = round(state[1], 1)\n",
    "        discrete_pole_angle = round(state[2], 1)\n",
    "        discrete_pole_ang_vel = round(state[3], 1)\n",
    "\n",
    "        return (discrete_x_pos, discrete_x_vel,\n",
    "                discrete_pole_angle, discrete_pole_ang_vel)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out Q-learning on CartPole environment\n",
    "\n",
    "Check out the [environment page](https://gymnasium.farama.org/environments/classic_control/cart_pole/) for description about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://gymnasium.farama.org/_images/cart_pole.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://gymnasium.farama.org/_images/cart_pole.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02846489, -0.01901361, -0.0252371 ,  0.02659684], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, _ = env.reset()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap our environment with Discretizer\n",
    "env = Discretizer(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0, -0.0, 0.0, -0.0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, _ = env.reset()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [04:12<00:00, 19.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# create a Q Learning agent\n",
    "agent = Q_Learning(alpha=0.5, epsilon=0.2, gamma=0.99, \n",
    "                   get_possible_actions=lambda s : range(env.action_space.n),\n",
    "                   strategy=epsilon_greedy_strategy)\n",
    "\n",
    "# train agent using replay buffer and get rewards for episodes\n",
    "rewards = train_agent(env, agent, num_episodes=5000, \n",
    "                      replay_buffer=ReplayBuffer(512), decay_rate=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABCfklEQVR4nO2dd5hVxfn4P+/u4tI7LgjooiIIgoCICIoLKCDYotFgNJZvIuZnN8VgSYw1RI0So8agMWKPUbGhIiArRXqT3hdY+lJ3WRa2zO+Pc+5y9/Zybt338zz77L1z5sy8c+6cd955p4kxBkVRFCW9yEi0AIqiKIrzqHJXFEVJQ1S5K4qipCGq3BVFUdIQVe6KoihpiCp3RVGUNESVu5L0iEi+iPwq0XLUVkQkV0SMiGQlWhYldFS5JxkiUiAiR0SkxO3vpTjk20ZE/i0iO0SkWERWi8hjItIgwvT+LCLveITli0iZXaYiEflERNo4U4KQZMqzldQnHuFn2+H58ZLFLe83ReSY/Uz2ichkEekcbzmcxKPulohIpYj8w+16fRF5xa4DB0VkeoC03OtMiYisiU8pUh9V7snJ5caYhm5/d8UyMxFpDswG6gHnG2MaAZcATYHTIkgvkIV3lzGmIXCGnf4L4aYfJXuAfiLSwi3sZmBtnOVw5xn7mbQFtgH/TpQgTljn7nUXyAGOAP9zizIOaA6caf+/P0iSd7ml2Sla+WoLqtxTCBG5RURmishzIrJfRDaJyKX2tZEissAj/v0i8nkISf8GKAZuNMYUABhjthpj7jXG/Gin9XcR2Soih0RkoYhc6JbPn0XkIxF5R0QOAb8GHgJ+ZltbSz0zNMbsAz4GzrLT6Cci821Lbr6I9AvwHP5PRFbZz2CSiJwSQhldHAM+BUbaaWUC1wHveuTR2bai94nIGhG5zu3aCBFZbD+LrSLyZ7drLhfGzSKyxbZOHw5FMGPMEeBDoIdbeieJyMcissf+ve+xw+vaPbyW9vdHRKRCRBrb358UkbFhyPtLEdkCfCcimXYdKxKRjcCIEJ+tL34K7AZm2Pl1Aq4ARhlj9hhjKo0xC6NIX/GDKvfU4zxgDdASeAb4t4gI8DnQSUQ6usX9OfAegIgcEJEL/KR5MfCJMaYqQL7zsZROczvN/4lIXbfrVwIfYVnj/waeBv5rW1tneyZmK6VrgMV2z2Ei8CLQAngemOhhXbvuuwqr4bgaaIWlNN4PILcv3gJusj8PBVYA293yaABMtst5InA98IqIdLWjHLbvb4ql+P6fLZc7FwCdgMHAn0TkzGBC2fleD6y3v2cAXwBLsaz6wcB9IjLUGFOG9ZtcZN8+ANgM9Hf7/n0Y8l6EZUkPBW4DLgN6Ar2xFLS7nKNF5Mtg5bG5GXjLHN/n5DxbzsfsxmOZiFwTJI2/2HFniUheiPkqxhj9S6I/oAAoAQ64/d1mX7sFWO8Wtz5ggNb293eAP9mfO2JZ4/VDyHMd8Osw5dwPnG1//jMw3eP6n4F3PMLygVK7TNuwrOVWwC+AeR5xZwO3uN33K/vz18Av3eJl2GmeEoLMeUChW5k7AR8ANwC/AvLtaz8DZnjc+y/gUT/pjgVesD/n2r9JO7fr84CRfu59Eyizn0kVsAnobl87D9jiEf9B4D/25yewGsQsYCdwLzAGqIvlCmkZhrynul3/zr0+AEPsOFlh1pGTgUqgg1vYQ3ZafwZOwGpUSoAz/aRxHtAIyMZqKIqB0+LxLqb6n1ruyclVxpimbn+vuV3b6fpgjCm1Pza0/7+HZfmBZbV/6hYnEHuBgAObIvJb2xVyUEQOAE2weg8utoaQD8A9dpnaGmNuMMbsAU7Csubc2YxlrXpyCvB3uydyANgHiJ+4gXgbuAsYCEzwkcd5rjzsfG4AWgOIyHkiMs12lRzEckO19Ehjp9vnUo7/Rr54zhjTFEvRHsFqdFxynOQhx0NYfmywLPM8oBewDKu3cRHQF8sIKApDXvff7ySP756/TajcBMw0xmxyCzsClANPGmOOGWO+B6ZhNSBeGGPmGmOKjTFHjTHjgVnA8AjlqVWock8vvgVaikgPLCX/Xoj3TQF+YrsBvLD963/A8k03sxXRQSyl6sJze9FwthvdjqXI3DkZy7r3ZCtwu0fjV88Y80MY+YGl3O8AvvLRAG4FvvfIo6Ex5v/Z19/DcoO1N8Y0AV6l5rOICGPMFizr++8iUs+WY5OHHI2MMS7l9gNWQ/ATW96VWM9tBMddMqHK6/577QDau30/OcIi3QSM9wj7McK0XBgceNa1AVXuaYQxpgLL7/0slm98coi3Pg80Bsa7BidFpK2IPC8i3bG6xRVYM02yRORPdvxA7AJy/TUYHnwFnCEiPxeRLBH5GdAF8OXXfRV40OX/FpEmInJtCHnUwLYmLwJ8DXZ+acvzCxGpY/+d6+Y3bwTsM8aUiUgfrF6SIxhjJmM1dqOw3DmHROQPIlLPHug8S0TOteOWAguBOzmuzH8Abqemcg9X3g+Be0SknYg0A0aHWw6xBsTbUnOWDMB0YAvWb5glIv2xeh+TfKTRVESG2oPHWSJyA9ZYgldcxRtV7snJF1JznrCn2yAQ72ENkP7PVvZA9dzjC33dYKyZK/2wustzRaQYmIplna/Hepm+xpouuBnLRxzMDeN6qfeKyKJAEY0xe7EG8H6L5SJ6ALjM5VbwiDsB+CvwgVgzc5YDlwaRxV++M40x232EF2O5CUZiKdqddp7ZdpQ7gMft5/QnLGXoJM9iPYMs4HKsgexNQBHwOpZLzMX3QB2shsD1vRGWEnURrryvYf3mS4FFgOe6gIdE5OsgadyMNUhf7B5ojCnHGnwfjlW/XgNuMsas9pF2HeBJLKOiCLgby2Wpc91DQIzRwzoURVHSDbXcFUVR0hBV7oqiKGmIKndFUZQ0RJW7oihKGpIUW3i2bNnS5ObmRnz/4cOHadAgos0LU5LaVl7QMtcWtMzhsXDhwiJjTCtf15JCuefm5rJgwYLgEf2Qn59PXl6ecwIlObWtvKBlri1omcNDRPyuHla3jKIoShqiyl1RFCUNUeWuKIqShiSFz11R0oXy8nIKCwspKyuLOq0mTZqwatUqB6RKHbTMvqlbty7t2rWjTp06Iaeryl1RHKSwsJBGjRqRm5uLdYZK5BQXF9OoUSOHJEsNtMzeGGPYu3cvhYWFdOjQIeR01S2jKA5SVlZGixYtolbsiuJCRGjRokXYvUFV7oriMKrYFaeJpE6pclcSxqaiw8xa77Wrr6IoDqDKXUkYA5/L54bX5yZajLRj586djBw5ktNOO40uXbowfPhw1q5dG1FaY8eOpbT0+EFVw4cP58CBAw5J6gzjxo2jc+fOdO7cmd69e5Ofn+83bm5uLkVF8TMoEvm8VLkrShphjOEnP/kJeXl5bNiwgZUrV/L000+za9euiNLzVO5fffUVTZs2dUja6Pnyyy/517/+xcyZM1m9ejXjxo3jxhtvZNs2Xyc0Ok9FRUXA64l8XqrcFSWNmDZtGnXq1OHXv/51dViPHj248MILMcbw+9//nrPOOotu3brx3//+Fzi+/P2nP/0pnTt35oYbbsAYw4svvsj27dsZOHAgAwcOBI5bvgUFBZx55pncdtttdO3alSFDhnDkyBEA8vLyqrcTKSoqwrVvVFlZGbfeeivdunWjZ8+eTJs2DYA333yTu+66q1reyy67jPz8fCorK7nllluq5X3hhRe8yvvXv/6VZ599lpYtrfO+e/Xqxa233srLL78c8jPbs2cP11xzDeeeey7nnnsus2bNAmDevHn069ePnj170q9fP9asWVMt77XXXsvll1/OkCFDePPNN7n66qsZNmwYHTt25IEHHqhOO5TntXDhQrp37875559f/fs4gU6FVJQY8dgXK1i5/VDE91dWVpKZmVkjrMtJjXn08q5+71m+fDnnnHOOz2uffPIJS5YsYenSpRQVFXHuuecyYMAAABYvXsyKFSs46aST6N+/P7NmzeKee+7h+eefZ9q0adXK051169bx/vvv89prr3Hdddfx8ccfc+ONN/qVzaVwly1bxurVqxkyZEhAd9GSJUvYtm0by5cvB/Dp3lixYoVXeXv37s1//vMfv+l6cu+993L//fdzwQUXsGXLFoYOHcqqVavo3Lkz06dPJysriylTpvDQQw/x8ccfAzB79mx+/PFHmjdvzptvvsmSJUtYvHgx2dnZdOrUibvvvpv27dvXyMff87rjjjt4/fXX6devH6NHh31crV9UuStKLWHmzJlcf/31ZGZmkpOTw0UXXcT8+fNp3Lgxffr0oV27doBl6RcUFHDBBRcETK9Dhw706NEDgHPOOYeCgoKg+d99990AdO7cmVNOOSWgcj/11FPZuHEjd999NyNGjGDIkCEhlTPco0OnTJnCypUrq78fOnSI4uJiDh48yM0338y6desQEcrLy6vjXHLJJTRv3rz6++DBg2nSxDratkuXLmzevNlLuft6XgcOHKCkpIR+/foB8POf/5wvv/R1Lnz4qHJXlBgRyMIOhUgW9HTt2pWPPvrI57VASi87O7v6c2ZmZlBfsq97XG6GrKwsqqqqAGrMzfaXv3t893uaNWvG0qVLmTRpEi+//DIffvghb7zxRo17u3TpwsKFCxk0aFB12KJFi+jduzeVlZXVVv0VV1zB448/7jP/qqoqZs+eTb169WqE33333QwcOJAJEyZQUFBQY+dGzy16Q3l+vp5XLM+wVp+7oqQRgwYN4ujRo7z22mvVYfPnz+f7779nwIAB/Pe//6WyspI9e/Ywffp0+vTpEzC9Ro0aUVxcHJYMubm5LFy4EKBGQzNgwADeffddANauXcuWLVvo1KkTubm5LFmyhKqqKgoLC5k3bx5g+eurqqq45ppreOKJJ1i0aJFXXg888AB/+MMf2Lt3L2C5ciZMmMDtt99OZmYmS5YsYcmSJX4VO8CQIUN46aWXqr8vWbIEgIMHD9K2bVvA8rPHgmbNmtGwYUPmzJkDwAcffOBY2mq5K0oaISJMmDCB++67jzFjxlC3bl1yc3MZO3YsAwYMYPbs2Zx99tmICM888wytW7dm9erVftMbNWoUl156KW3atKkeAA3G7373O6677jrefvvtGhb1HXfcwa9//Wu6detGVlYWb775JtnZ2fTv358OHTrQrVs3OnfuTK9evQDYtm0bt956a7VV/5e//MUrryuuuILt27fTv39/Kioq2LlzJ0uXLqVVK5/nVwDQvXt3MjIsu/a6667jxRdf5M4776R79+5UVFQwYMAAXn31VR544AFuvvlmnn/++RrlcJqXXnqJUaNG0aBBA/Ly8qrdO9EisewWhErv3r2NHtYROulS3tzREwEoGDMiaNxUKfOqVas488wzHUlL91kJj4qKiurG4J133kmZlcI7duygTZs2AIwZM4YdO3bw97//3Suer7olIguNMb19pauWu6IoaUFWVhZvv/12osUIm0mTJjF27FgqKio45ZRTHHMBqXJXFEVJINdccw233HKL4+nqgKqiOEwyuDqV9CKSOqXKXVEcpG7duuzdu1cVvOIYrv3c69atG9Z96pZRFAdp164dhYWF7NmzJ+q0ysrKwn6hUx0ts29cJzGFgyp3RXGQOnXqhHVaTiDy8/Pp2bOnI2mlClpm51C3jKIoShqiyl1RFCUNUeWuKIqShqhyT0ImrdjJL/6tJxQpihI5OqCahNz+9sJEi6AoSoqjlruiKEoaErJyF5FMEVksIl/a35uLyGQRWWf/b+YW90ERWS8ia0RkaCwEV1KP/YePsftQWfCIiqJETTiW+73AKrfvo4GpxpiOwFT7OyLSBRgJdAWGAa+ISCZKrafnE5Pp8/TURIuhKLWCkJS7iLQDRgCvuwVfCYy3P48HrnIL/8AYc9QYswlYDwQ+EUBRFEVxlFAHVMcCDwDuGy3nGGN2ABhjdojIiXZ4W2COW7xCO6wGIjIKGAWQk5NDfn5+WIK7U1JSEtX9yYq/Mvkr751TD9O6fgZ/PL+e901JhKfsofx26fobB0LLXDuIVZmDKncRuQzYbYxZKCJ5IaTpa4d8r12UjDHjgHFgHdYRzUEMqXKQQ8h8Yx1i4a9M/sp7+JuJbDhYlbzPwrNcQcrpTtr9xiGgZa4dxKrMoVju/YErRGQ4UBdoLCLvALtEpI1ttbcBdtvxCwH3Y7/bAdudFFpRFEUJTFCfuzHmQWNMO2NMLtZA6XfGmBuBz4Gb7Wg3A5/Znz8HRopItoh0ADoC8xyXXFEURfFLNIuYxgAfisgvgS3AtQDGmBUi8iGwEqgA7jTGVEYtqaIoihIyYSl3Y0w+kG9/3gsM9hPvKeCpKGVTFEVRIkRXqCqKoqQhqtwVRVHSEFXuiqIoaYgqd0VRlDRElbuiKEoaospdURQlDVHlriiKkoaoclcURUlDVLkriqKkIarcFUVR0hBV7oqiKGmIKndFUZQ0RJW7oihKGqLKXVEUJQ1R5a4oipKGqHJX0o7VOw9RVeV1bK+i1CpUuStpxcLN+xk2dgavzdiYaFEUJaGoclfSisL9pQAs334owZIoSmJR5a4oipKGqHJPYoypXX7jdbuKOVqhZ6krihOocleSgj3FR7nkhen86dMViRZFUdICVe5KUnCorByA+QX7EiyJoqQHqtwVJUVZsvUA/1uwNdFiKElKVqIFUBQlMq56eRYA1/Zun2BJlGRELXdFUZQ0RJW7oihKGqLKXVEUJQ1R5a4oipKGqHJXFEVJQ1S5JzG1bIGqkkTMXFdE7uiJ7C4uS7QoSoSoclcUxYs3fygAYMmWAwmVQ4kcVe5Kwim2V6d6UlB0mAc+WkpFZVWcJVKU1EeVu5Jwrn7lB5/h93+4hA8XFLK08GCcJVJcqGcwdVHlriScdbtLEi2C4oFIoiVQokWVu5K06ICyokROUOUuInVFZJ6ILBWRFSLymB3eXEQmi8g6+38zt3seFJH1IrJGRIbGsgBK+qNWpKKETyiW+1FgkDHmbKAHMExE+gKjganGmI7AVPs7ItIFGAl0BYYBr4hIZgxkVxRFUfwQVLkbC5dTtI79Z4ArgfF2+HjgKvvzlcAHxpijxphNwHqgj5NCK7UD9cokHnWNpS4h+dxFJFNElgC7gcnGmLlAjjFmB4D9/0Q7elvAfZPpQjtMUdKOsvJKDh4p52hFJbmjJ/L85LWJFskR1BOW+oS0n7sxphLoISJNgQkiclaA6L7qhVf7LyKjgFEAOTk55OfnhyKKT0pKSqK6P1nJ/z6fDB8O52DlTfZn4Uu+eXPnAVBaWlp9vfjQEQAWLVpE66wjIZVr1fYKAHbv2hWX5/D47CNsPFjFS4PqA/Dv6evoVWe7I2mHWq9jUc6iImtl6ooVy6lbtNrx9P2Rru9yIGJV5rAO6zDGHBCRfCxf+i4RaWOM2SEibbCserAsdffTA9oBXrXdGDMOGAfQu3dvk5eXF770Nvn5+URzf9LxzUQALrooj8wMb+Xut7z2fUn7LDzls78D9DmvD8z8nvr161dff2HFLDh4gHN69eLgxqUhlevgkm3w4xJOzMkhL6+nwwXw5ha7DP3794fvJlOnTh3Hnn/Qeh3D3/u9LQtg9y66dj2LvLNaO56+P9LuXQ6BWJU5lNkyrWyLHRGpB1wMrAY+B262o90MfGZ//hwYKSLZItIB6AjMc1huRVEUJQChWO5tgPH2jJcM4ENjzJciMhv4UER+CWwBrgUwxqwQkQ+BlUAFcKft1lGU8Khlo3lzNu5l16EyruzRlvLKKoqP1a7yK84SVLkbY34EvPq3xpi9wGA/9zwFPBW1dIoCSC2Z6D5y3BwAruzRlt//bymfLillxMWGDB+uufihDUyqoitUFcUBXCrwQGm5Ixudfb50e410400taU/TGlXuSq3HGINx0AX04nfrHUsrHfl2xU4Kig4nWoy0R5W7kvQcORbbIZsOD37FTW9EN+bvbugW7i+NTqA0Z9TbC8l7Lj/RYqQ9qtyVpMVlS1//2pyY5zVjXVHM81CUeKLKXVEUv9SyCUtphSp3RXGaNFCIohsQOELXP33Dc5PWJCRvVe5JjJODfKlIKhU/hURNKHuKjyZahLhy+FglL01LzAC7KvdaQll5JWt2FidaDL+UlafROjc1en2y+1AZ5z41JdFi1BpUudcSHvjoR4aOnc6B0mNxz3tT0WFWbj8UMM6Ulbu9wqKZa636NfnYXcus9kQT1sZhSuoyv2AfAKXHKmlaP755D4xw2ls0bpl4u0lqNCbqo1GSALXcawnJ7r9+YUp67IOebiR5tVECoMq9lmDs1zRUV8eWvaXsPxx/F447RlVLwojF9gO6pUF8UeVeywh1ituAZ6cx4JlpFJUcpe/TU1m7K3kHY5OBGs2QA0pMm7XYcttbCxg3fUOixYgpqtxTkKoI9kKJxC1TfLSCqat2sfNQGa/P2Bh+ArUV1cxJz+SVu3j6q/idMJUIVLmnIP83qZRfjl8Q1j0ufaNd49Sitq91UCJHlXuK8t1q76mDSuJwus1MljZY25bURZV7BBytqGTQc/l8v3ZPTPPR90pJFNrDS31UuUfA9gNlbCw6zKOfLU+0KGHjxDs7bc1uVu8MvCjJCaKxGlU3KbUdXcRUS3Cye33rf+YDUDBmhHOJpjjaywqObkYWX9RyrzXY6ieF3i8nVqiO/6GA9+ZucUSeeJKOjYWuW4gvqtxrGalsPX2/dg8Dn8vnaEXom4w9+vkKHpqwLIZSpTeqkFMXVe5KyvDHT5ezqegwOw+WJVqUgDipDhN2QHYMjIBUNixSEVXuiuIAny/Z5mh6qgaTl2Q3Llyocq8l1Pb5yg9PWFa9M2YsmLhsR/VnVczpy4KCffT9y1QmLC5MtChBUeVeS4h2hWqqNw7vzt3Cta/OTrQYScOK7QfZuKckrnmmw9z5VfaBNwsK9idYkuCocq9lxPv9WlZ4MOJ7U7U9cULuWJd9xIszGfS376NK47a3FjDixRkhx091AyHVUOVeS4h2j5JIra7LX5oZVb7h8pXtHkk2IzFV/LSeBKo2k1fuYkWQE7aU46zYfpA3Zm6KW36q3CMgXps5xSIbSYe+cQAmrdiVaBG8mLNxL33/MpXPl25PtCiho/u5+yaKl3LEizN5/MuVDgoTGFXuSlqSSA+Apw5znR+7aHP4ftqEuTLUhRKQVGioVLlHQCpav7F+V1+etp7c0RNjnEtq4MSzTr0aVrvYW3KM3NETmbwy+XqKLlS5O8yB0mMcORb6CspYsCfAKfORKo1gFuSzk9ZEmHKgPH1nqgNzcSDK1uXw0QoOHimvmWQ6tFh2IVbusHpj438oCDuJJ79cGRcdocrdYXo8PpkhY6ObhRAtw8ZO91KMqhCVSIi02pz71BTOfuzbmmklSR2M6mxgBwrx+sxNvDEr9gOrqtxjwNZ9RxKa/97Dx/xaFJFaT05bXdFYLqlmAUaiDhKtB6N9xKUJ7r0GYuDf8qNOI9rnU1kV+19YlXuasmpHzQOtnZjhY4yp0Wjkjp5I/prdEc0C2eBnAc3GosOs2O57bry/F6Kisirs/JXay4HS8uCRQiSZN1ZT5Z7kTFu9my9/jH4KnRNV8IcNe3n08xU1wm75z3zueX9x2GnN2bjX77URL3rPjV9RVMm2A1aPyL2dmrNxL6c//HVMtxaIlhTraMSMaHpcW/eV8sLktUlzpmy0kyriUQxV7knOrW/O5673wlee/vjl+AUBB1wDEY4rZd2uYorL/FtIT05cFVbey4p85z1rfREAszfUbCxCffVqk9VvjOHBT35kboCGNVm57a0F/H3qOjYVHU60KEBqHFweVLmLSHsRmSYiq0RkhYjca4c3F5HJIrLO/t/M7Z4HRWS9iKwRkaGxLIASHgs37+df328I+z5jwrO8LnlhOje9MS/sfPyxeHdFwOuRvmvPfuv8LB8niaTbv2FPCcu3+XZtvT9vKz8bNydaseLOsQqrEU5+lZo8hGK5VwC/NcacCfQF7hSRLsBoYKoxpiMw1f6OfW0k0BUYBrwiIpmxED7dicaf53VvAt6KxVsOOJbWrtLjBXBvZPy1N6EWd8W2OJwFa///aGEhu4tD24Ygmk7/4L99z2X/cGbbh1SwUBNBtG6ZeEwKCKrcjTE7jDGL7M/FwCqgLXAlMN6ONh64yv58JfCBMeaoMWYTsB7o47DcCcXJCl9cVs6hAO4LJ9h3+BhlbqcXRSJ9ImaoxEKvLNxc0zcfzwGxkqMV/Gr8grjlFw2puFAvmfl4Yc0tguPRZoZ1QLaI5AI9gblAjjFmB1gNgIicaEdrC7j3+wrtMM+0RgGjAHJycsjPzw9X9mpKSkqiuj9cdh62uohHjhzxm2+o8tzyjeVDfHNYA69r06dPD5heoDx27NjJtGn72HCwiifn1LQWC7duJT9/d0jyrV6zpjq9ZVV7gsYPpdyhxjl8uNTntTlz5rKpgWWXFGy25iwXFGwiP//4gRm7d+3ymc81/5xd41nvc5u2Gk0dOnjwuBtk566dNdJaX3C88d5WdChoPvn5+dUv//Tp06mTEVjRhlIHj1QY9h7x1ij+7t29y6ozq1auosmBdRHl73lta3GV32suPN/lLYcqyWmQQWmp9TtN/2EuW5s45wgI9zdfu8X6LUtLrbq5b9/+kNJ4K395je/u9TVW+itk5S4iDYGPgfuMMYcCtOy+LnjVKmPMOGAcQO/evU1eXl6ooniRn59PNPeHy6aiwzAjn3r16nnn+421BD9keXzFt8MGDBgA337j97q/vAHatGlNSfNWPDnJezC2Xfv25OV1CUmuzp06wfJltGnTmu5ntYZFgS3Papm+8b8VQV5eXsDrrjgNFk+HkmKva+eddx65LS0FfYudTm5uB/LyOlane2JODnl5PX3m4/7cxq2bA/v2eoWHjJ1+kyZNYL+1d0zrnNbk5fWojrJx5iZYbW0YlZ2d7T8f99910kQwVh3IzrKU2Za9pVzx8ky+uOsC2jevH7QeuIdf+fIslm494JWlP1k+3rEYdm7nzC5nktfDyzbzm0+ga2t2FsOs4waLr/vy8/PZ1eBU3pmzhfdH9eWWRydxSZcc6tcXKD3My8uqWPDIYN/yhIpbnQj3N986uwBWrqB+/fpQephmzZqRl9e3Zpx9pewpOUqvk5tV59WyRQvYc9ygqq6vxE5/hTRbRkTqYCn2d40xn9jBu0SkjX29DeCSvBBo73Z7OyCFtsNLHwocnlkQyhmYxpiY+2krqrxnuHi6V6oCyLBw835yR0/0O9c+WiYs3lZjFo5TT+N/C7dyoLScCYvDP9LPl2IPBWPis+DGysswdUs5f/h4Gcu2HeRoueVKXLh5PxvtulxUEsXq0hjgaeOWV1Zx4TPTuPqVHxIjkBuhzJYR4N/AKmPM826XPgdutj/fDHzmFj5SRLJFpAPQEXBu2oQSMv46V5Ho3lDvmbJqd8z9iRc/P52PFgY+5mzijzv8XnOddzpjbXA3U6S8P39rzNKOJ/f9dwkdH/4qLnkt2XqAt1d6K+9UGdT98sftdHz460SLUU0olnt/4BfAIBFZYv8NB8YAl4jIOuAS+zvGmBXAh8BK4BvgTmNM8q5FjoBUqWxODoodrQhtPnhZeWVQSzVUSzDQYOfXy7yV9/YD4W37YKjZaBUUHWZvibUG4POl2/lbFNMkS4/6n7rpng9Yc+39WdaJqmruNSdOhrtXHXN6UHfuxr088NFSR9N0/30CnSVQEqA+xIqgPndjzEz8z8zy6fwyxjwFPBWFXLWC12dsTEi+4bwzf/h4GWApu5/08uN79SBRjV+/Md+FFM+f0sh7Lp+6dTJY/cSl1atufzukU0SyVBkY9Ld87r/4jBrhxs4nOyuDNU9eClhz7f/1fc26IHbcsvJK6tbRmcRO4MT8/uqziMO8b+6m+K+g1hWqEeCURRHuKs1wCcUt8/HCQnJHTwy4mjRcgql2J57e5n2+Z9KEi2fvoKzcmRWrRysq2bjnML/7n29L0d1K9TXX3mUt/+mzFV7XlCQgykocjym4qtxjxNNfrYrb0nZjjE8XQigDoK/aq1V3hHDG5+EQu5bBDPcPF4Tmjw6UzvrdNQdDk9lTtqko8oHbLW6NWCLLeMiB9RiR2kT7HdzoyzGSuL65UOUeI8ZN38iUVaHNJfdHqC/zut0l/OO79V7hTq9D+cdU7zw8MQS3SkZ/sswhiZIfA7wzZ0uixYia7n/+lu5//jZ4RAdxovqu3VXs6CJBp16pUAyvaFHlHkPi5Xv2Ne3PGAiy9sWKF0Y+lSGWx6liB2ucon2+xjgna6jp+IoXqJzu0eO5aDQWeYX7rJ1wvQ15YToj/xXY1/7Vsh3kPTstpIF+V4yNUU4zVrdMkhILpf3OnM3si+aEGB/4sw58VaxQ3uV4L0hPVldLVZWhvNJzZkfNOGOnBF7VCbB820FyR0+sPkA7GMn6PCIl2Ht01cuzHMnHdSSeP/7w0Y8U7C3l8LEKysoreX3GRqpCndFlR6uqMnwRwbkGsUSVe5LwyKfLufeDyLb29afEw7G+QqnKoaYXLyW061BkWxdHy8OfLnNkPvO39uHKez0a9RrHwCWpRvds3ELBs/4kS9HcxXh+8lqenLjK5wE0e4qPctTPgPu3Pg7KfnbSaqdEjIiw9pZRLHzNljHGsGjL/qjS3V8ameUer82vQvUTOiVPsFT6/mVqyHGd5P15Di1Q8qPd9pT4brSSaS8vJw6QSRZcc9AFOGQf6u3rmMBzn5riN42ycu/4L08Lf2ttJ1HL3QGKy8q5673FXPPP2YkWpQbhTNl0Sm9Y2w84lFgY5K8Jf/Da4FyjsP1AaFv5hoL78zN+whONExPBkqg41bhemcVRGmrJgCp3B/jNh0uZ6GPFpC8qKqsc36vDr1smhHvDGT8I2S0TcoqBCdXvCfBjoe/DKXwRCwt4W5irY2sjno891hMOjlZEvjD+f/b2Fgs37yN39ESvqbeeJFOvyoUq9zAwxrDtwBGvShnO0V+nP/w1l/59evCICeKV/PXW7n0+CLUn4NRLG+2MhGDs8PFbOo7XmSmhzMg4HsddvLjOlolBmvG01L9ZvpNOj3wT1j2+6ver9srhx79c6Yhc8USVexi8O3cL/cd8xzKPI8zCVRBrd/m2ApYHOBXIdchEqHkZ8JLTF+4VurLK8Mw3a/zOUgj1hU/G7rYvXp+5ifkFiet+h/uc4umWcSqrhZv3++2pLg9xllAkfLfa/z4vobJhTwmT7YHS6Q5vMqcHZCcZ8wssBbtxT/QWZbiDr78M8wSfbfuP+N0atoZP1/5yyQvTqweWjvgYHAJYvbN2TtmLFb4WnoGnzz2+D/NX4xfw3CTnzpW95p8/VK+C9jQOPI2IrQ5tKREpyzxce4X7U9vVVuuVuzGm+vDdePJKhCPpoSrOg0f8r8r7ZFGhzxdpVZD5wCG7wFW5O4Z73YyHW2bKql28NG29o26Ztbt8u/k8+XRJ+PvU+8PzPQll64xQz7f1xedLwp89tGTrAXJHT6SwODb6p9Yr99dnbOKMR76usQVruMRDl7kqqxN5HSqr4Jp//uCVnhMWtzHxtzbDJR5Lv/0R7tz8tbtKeHt2AeD/9ykrr4xKMQHM27SPd+ZsjiqNaIllj2/M16HOOY+sbkxdHd5sLRFrZSzAj0Wx2Q641s9zd7ku5m7ax/BubUK6x6sORlQpE6sAfc2ldmpwUd0yx4mkofN8fn/8bAXfrtxFTuO6PuPf9tYCZqwromDMiEhEBOC6f9Wcxutv8Hzf4WM0b3BCRHk41fNYvfMQbZvWo1HdOiHfE8r+MpHs9hqpIVPjN47R+1LrLXcXd7y7KOD1d+Zs5jO76/XiVGtpecHe+PkIXfXOXQGXlVdWt/4RpxvV3b5JFt0+2ceqQSeJ5771M9YV+T19asa6IsD3ASZOM/hv+V5hoS67d+pxDRs7g5veiM3hblNWxbbOxBNV7iHyyKfL/V7zV2ed9JEaA5f+fQY/f31uddgz36zhjncXMWfj3pBlChTPKVWVLCdV3fZWeIPQgZizcS+zN3g/52CUVzr/LPxVqz9+5r+OOsX+0nIqqwyVbufY3v3+Yh7/wv9Uwe0HjpA7eiLf+5hx4r6WIZxqs3jLAa+wSh97/oRDQdFh9hQf79Em4dT1sFDl7gD+lFmgyupvO+BAe8Cv2nGIeW4nuuw8ZI3m+9pwLJKKGehQ6VCZsa4oaSx3f0Sy2+TIcXO4/rU5HvGclMot3SBP0N9VX4OIf/58BUd8LKWPhhEvzqg+ocvFG7M2+Y2/xD5C0Nc+/v/v3YUAvDt3M3M3hd94unPlyzOj2vNnjcfAb7LX42CkpXI/WFrudyFOsvMXPwM/vhRSZob180Wy4tWXYnJCWX28qDDlfe7uq00nLA58EHeiCKUX8er3G3jzhwLG2wOyTrE6zHfLNYDta32H69zRhycsj/qsVvd1ImURzIALdKi608Rjb560VO4/ffUHho71vwr0tIe+Inf0xJjLEYlbxt8eKb4UZqadfkWEb8VZj05iTwx2Vkz22TLBcH/WS3x0/6vjxV4UnwiwJoQ1B6564fR2F+ESrD44eZiGCye2342lW2bDnsMxd/ukpXJfF2QfCCcr+7crdvodWP14Ufjzdt0Vtedp8J5k2KdxROpOKTlaQbHb/F9fvvuISG3dXoNAMyii8e8GItgmZH7dMhDy3vDBiKe/+b4PljianlPHW8Z6QD7Y+x0ttX4qpCdVVYYdh8po27ReSPFHvb3Q77VIKsdmt4bi7McCH2vm9HxtfytawyUpz7yMAZ3/GN7eJaESzUDw8BdnVH/+Z35it5wNlYK9ka34Liuv5FBZOQdKy5m0fOfxcB9K8zM/i4yeDLBnzNshzPuPxgX55g8Fkd8cArVaufsaOBs7dR0vTl3HjAcG0r55/QRIFTouo/L7Nc7uexEt7jMOkpFwmsTPlmwju05ydXD9yV8cA/dGuCwo2Md/Yqy0XNz0xjzmbdpHo7pZFJcd74GG8/u+PtP/QHCqU8uVu3fYrPXWnOFdh8qSX7nb/z1H+SPFsfNE08gvs7+0nH/ZOwMmC/6erpPTLj+JsBd321sLwu65RbpXk2vmWCK2D3GRjFv9ukgukyTOGIKfr5gsRLM3dag4MRXSSseRZJQAHHZ4eqNT+BqjiMVc/2TBkS07ok/CJ2mt3IPtF5Msi21CoczH2Y2BrIZILIp0W8QUKbtTwK30rIM7NzrF85PXOn7IeyQkszUdT9JauZ/zpP8zDyF+kzqOVVSxeMt+3p+3xdF0XYtDfJFI/epE1ksDlC1agvlZXZuqJSvJ2nS6tuWIN56zThK5MVwyUat97q792WPN01+tisnIuL9DPyLFqQbh1v/MjzqNjUXOlk1RYoETr0xZjDxsaW25B+MfU70PS4jFgo8V20M/39MpjkU01zd5bMJk9ewkg8sp3Hncgfb2T0dSzS2zvUT3c3ccX7M6Ark6IsojQcog2IG+yU4S6FCfvOjDIIg342eHt+/6uOnJNdsn1sSz7mzbH4dzeCOkViv3eBDrQ56dJJlmuazdnZx7A328KPF7zYRyqlA4HKwli85iwbYDR3hjVkGixfBJrVbugZSZk3pu4ebEHcIcDskw08FFss0td5HofVpiQTI0WE7S56nAEymc5tsVO4NHCsD+stjUqVqn3K979fiJM+7b5/qiuKycf+ZviGqRhJBcFrESHcnaBVeOU+xwzyYYc4PokWBsPBgbn3utmy0zL8QZMgI89sVKPlpYyF+/CfX8RSXdSYaG2kkR5jq1WZySdNQ6yz1UDLDFgWP0IjmXUUlenFrFmyzML9iXcrNLlNAIqtxF5A0R2S0iy93CmovIZBFZZ/9v5nbtQRFZLyJrRGRorASPB6Fa+UrtIRks93T0+yvOE4rl/iYwzCNsNDDVGNMRmGp/R0S6ACOBrvY9r4hIpmPSxhGnjBk1ipRkRkTXc6YrQZW7MWY64GnCXgmMtz+PB65yC//AGHPUGLMJWA/0cUbU+FLq0MZMkZ6SpCQnRUH2K0pFth8MfDiIkppEOqCaY4zZAWCM2SEiJ9rhbQH3U4QL7TAvRGQUMAogJyeH/Pz8CEWBkpISv/eHk6573L994f8QjnB49Yvk3qdEqd0k4wZktZFo9J8/nJ4t46uH59N0NcaMA8YB9O7d2+Tl5UWcaX5+PjXu/+b4+ahe6X7j/+zUvLy86uvNmjeHPdEfgpHboQOsWxt1OoqipC/R6D9/RDpbZpeItAGw/7tOdS4E2rvFawfE/phvYMrKXeSOnsh2t5PrXRytqCR39ERenxH6wpgKh/agTqUVqoqipA+RKvfPgZvtzzcDn7mFjxSRbBHpAHQE5kUnYmh8MH8rAMu3eW/S5TqC68mJq0JOb6Z9IlO0zN2oM24URYk/Qd0yIvI+kAe0FJFC4FFgDPChiPwS2AJcC2CMWSEiHwIrgQrgTmNMXI+MeewL7wNvEzk1eZuPnoSiKEqsCarcjTHX+7k02E/8p4CnohEqGnwpU10yrihKbaNWrFBV1a4oSm2jdih31e6KotQyaodyV9tdUZRaRtor944Pf+VzeqQv5ugOeYqipAlpr9zLKw2TV+4OHhEYOW5O8EiKoigpQNord4D9SXTCkKIoSjxIeeW+YU8J+8sCn2Ty3wVb4ySNoihKcpDyJzEN/tv3AFx8ZuMES6IoipI8pLzlriiKonijyl1RFCUNSWnlvmZnsds3ncuuKIriIqWVe1l5XPckUxRFSRlSWrnrqe2Koii+SWnlnuGm3RdtOZA4QRRFUZKMlFbu7uzThUqKoijVpLRyV7eMoiiKb1Jbufs8j1tRFEVJaeWekdLSK4qixI6UVo9quSuKovgmtZW76nZFURSfpLRyz1DlrihKihMrNZbSyj12j0VRFCU+PHdRvZikm9LKXd0yyc83913I1b3aJloMRYk5XdpEtu14i3qxUcMprdwzVLsnBfdd3NEr7ITMDE5t1YDOrRvz/HU9alyb+9Bgnr/u7DhJpyQjdTJT491tlG0deZGdFVxVJtvsvSQTJzySpXo889PuiRYhYbRseAL3XXyGV/jqJ4Yx5f6LfN6T07gumfaASfd2TSLK97Wbege8fufA0yJKNxpCUQC1hbZNA7sa+p3WMk6SHMdlhPz0nHYh35Nh19M5Dw7mm/suDBg3M8mMTa2NDnBd7/ZeYVN+MyAmebkPIvc6uSlv/V8fv3EbnJDpFfbgpZ1pUq9OVDLcPeh0WjXKBuDpn3Tzut6qUTYZGVL9YvjC1etq37y+17V7Bnv3BDy5pEtOwOsdWjYMmka0eD7HK3ucFFV69ep4/16pQsGYEbx4fc/q75/e2T+B0vhm5LknUzBmBM9dG1mvMSuIaS4hKvffXuJtDMWClFbuybCDe07jbJ/hp5/YiBMb+b4WDe4KoGn9ExhwRiu/cT2fz2Xd23Br/w6cf2qLkPP7+8geXmENs7OY//DFFIwZwZCurUNOC+BZu5fjUu5VVcbrOQ3pksOCRy7miSu7hpTm9X2ON64/P+9kJtzRj2vc/PyPjDgzLBkBerRv6hU27hfn1PgejaE2vJv3c5vyW989nVD5y9Xd+PTO/iE1jsHo3LoRq58YVv395vNPCXrPFWcfb9xaxaDuuzivQ/Pqzy0anOA33tif9ajxPdr3MdjsvOeuPdtnj2XW6EHMeGBg9ffrzvU2BmNBait3Ezv13qZJ3ZDitWjgv8IEk+7qnqENNPbp0Jwz7cGad2/ry6lNQvvZPB/PSz/vxQlhug6u7NGW2y86Nax7Ar0D19q9nExbjCpj+OjX/WrEOSErg5YNs2nnw6r3xQmZx8v0xJVn0fPkZogIJ2RlcFqrBrRo6F8B+MOX5ek+xtOqUTZX9Yh8oPiVG87xCmte/7icd+SF71YyxmqU7hvckXkPDQ75PneF5FKAnVo3oq6bIVHXRy8wHix85GKvsE6tGwGWkRGoEclt2YCXf96r+nugnmQwRIJb5qef2LBG78VF26b1asiZ0/i4bvn4/50fsUzBSG3l7lA6vvyzn9zRz0fM4DTKzuJXF3QA4H4fvmgXHVo24HkPy8IfJzWpy/hbz+W5a8+mR/umXH6a5Q5w1VV3ReRuyRg/T6h985rWhT85T23ZAKhpKTmF60WpMlC3zvFqeM/gjpyR0yiitKBmg7/68WFMvv8ir0YuGBd2bGmna30/rVWDGt/Bsmxv7Htyjft+ek5oFtmXd1/gM9y94f390E6hiluN6/fOyBBObFzTODk3txn9T29Bt7beYxx3Dzq9+rOrLv3Mw9V4UYAeopO8PLh+DVdji4beyrtRXWuQ8/YBpzLejtvchwUvwIjubcKW4abzT2H9U5ey8enhNcIjaRta+jEs7h50OnUyhXNOcf7dcpHayt0h7Z6d5W2VBNraYNboQX6vLXtsKI9c1gWwXASjBpzK2T4GDQd1PhGAab/LCzpVMEOsl9U1EFRVXW5LRncXwoQ7+lf3Ovw9n98P7VztHgG49YJcn/FcVrZnOqe0aOAVN5iP9et7L2TKb467Hfp2aEGbJnVrKJaWDbP5jQ9/ZK+TmwZM22XJAdUDtUC13z/Q4J7nmMF7t53H2788D4CZfxjEJ3f0Y0Q3S0G4W1wv39Crxn0FY0bQJ8RG8CwfCvbln/eqIbt7gzWwUyufg4APDe9c47u/3/uv13Tjf7/ux7u/6uuloE4/sSEj+xxvpE5qWo+CMSPod7rVwLmMBc/34db+uT7zuvzsk7jH7Tf1h69GBqBBHQnoagQ4rZU1ntKhVQNyGtelYMwI/uZj9lWkbrMMEbIyM8jIkBrGQqDZef+064N7lJ/1bs+CRy6pEc816P7bIZ1Y91TNxsNpsmKaesxxRrv3OrmZV1gg/5wvZXH7RafS14cv+6Hhlr/3vKensOvQ0erwKrvSdGjZgC5tGvMJ26qvXd2rLWe2bswJWRk8+vkKv91J9+DepzRjweb9tG5Sl/M6NOfTJds5ITODoxVVXvedkJXBtb3b09G2kBvX9R5g/UnPttw+wHLHuOr3oM4ncu/gjpztwx/ty0ftzpkec4Cb1K/D7Act18HuQ2U+73HNPnC33hqckMnhYzWPVxx5bnvObNPYrwznndqCz+7sT6fWjXht+kb+Nnlt9bXrerdj877D/Ov7jdx+0ak1ZnG0bVqPtk3rcXa7plzSpXUNpdy4bh2/coM1W6jzH7+pETZr9KAaMyqe/Wl3fv/Rj0BNpXDpWTX98YPOzGHdruPnBf+kZ1tu6ZdLt7ZNGDXgNB6esIx3527x+zb87NyT/Vw5zg+jB5Hlo575SrNhdhaPXt6V/8wq8Lr2Dze3xJ8u68LjX670md/9l5zBS9PWV39v37weW/cdCSjjqAGn0u+0Flx0RitOa9XQZz0EOKttY5ZvOxTy3lMdWjZgU9HhgHEEoXGAiQiXdvPuIfxmyHFDxfW+x3NCTUordycs9zkPDqa1D/96MP/cX67uxoOfLKu2qB68NPCg3fu39WXQ376v/p7X6cTqz54W34OXnkmrRtnVB4AP8ZgZ4rLc3S2J90f15eCRck7IyqgO/+2QM9hxsIw9xUf5ZPE2PKlp8ffjsyXbefOHAp64sis39j3FzXViqvPz90IBPH/d2fzmw6XccF7wwTdfeFb8C05vyZ0DT+PW/h2YvHIXAPMevphKW55P7ujHmp3FiEjQxsUl992DO3Jt7/YUl5Uzbc1ustz89U3r+e5CZ2YI3cKcslnXY+bLOac08zIKrurZtlq5u1j4yMU08tHYutf1Z37anTpucjezffX1fcy26Xeah8FhP+TOrRuxemcxv+hr/VYn+end3Hjeybz43Xoa2vO9cxpn891v83zG9eT/LuhQQ7kP7ZrDpBXW75iZIVx+9kl8sXQ7AN/edxHHKqpYPG+W3/RchhLgVQ87nnh8dlSVbc+EokiX/mkIJ2RlUGkMywoPcv1rcxjY+USfcZvUq8P8hy/m40WFjPl6NQCPXdG1Rj7tm1njRI9f2bVGT881LnTz+bnBhXKI1FbuHt8HdT6R71bvDnpfp5xGTLznAjIk8HQ9X7hmZlzf52Su690+ZD/cqa0asvTRIXyxdDvX9zm5Rhe8e7umbHh6ODe8Poc5G/dVV4ROrRux4enhNeICNKxjfT+5xfEBxzqZ1iAkwM/Obc8ni7cx+Mwc2jevjzEm6PSvnic3o+fJzfjjZV288mtqK4+TgwxwXt2rHVf2aBu2b7JJfUuZeS6GysgQfj/Ucj2c1EA45/Q2NMg+XmV7ndzMZ68rGK2b1KV1k7rVPRcneWBYJ575Zg1g+Vv7ntqCL3/cUd0LcsfdineVw72Xck5OJgt3VZJ3RitKyiqqw90VO8Bdg06nRcMTuMpjgH7j08O9FFyHFvVZuvUA/7i+J7ktG3il5cn9l5zBvRefwRH7MPrRl3au/g3q1cnkSHmll2/aF1f2OImxP+vB3e8vZrVttLw4sgeHj1awt+Qo9U7IpJ7boG3bpvWqxz5uu7ADH8zbGjD9ds3qI2I1gr/OO4173l9c/X4M79aaTUWlNeIP69qarftLq+sewPmntfB63343tBN/+mwF9bMt2Vo1yub2Aady24XW7+n5rrRqlM2Gp4d7vQNZmRk+f49YIrGccRIqvXv3NgsWLAj7vjU7ixk6djpgtZR9T23BL/49t4b7IytDqKiqWcb3fnVetU/RxdZ9pazYfogpq3ZRuL+UD0adz/JtB7nsHzP54q4LuPylmYDlW40VB4+Us6zwIBd0DLzAIz8/n2OtOpPX6cSwZ79EyuSVuxhwRkuf4xPxID8/n7y8vJikvXnvYa59dTaf3tnfrwXrInf0RMCqB+t3F3Px89M5rVUDpoZozYaDe5krqwyTV+5iaNeckOdT+6L0WAVzN+7za52Gw86DZWw7cIRzTgm/gfVHNL/z9gNH2HmoLKIGP5FEU2YRWWiM8bmiL6UHVF0j5NmZcNP5uZyR04i5Dx2fOnVZ9zZMun8ATerVqTGq7qnYwVpMM+ys1jx37dl8MMqannRW2yYUjBkRdpc8UprUqxNUsbsY0rV13BQ7WIuGEqXYY80pLRow7+GLgyp2sFxFLlzukIvPDLygygkyM4RhZ7WOSrED1D8hyxHFDlYPyEnFHi0nNa2Xcoo9lqS0W6ZVo2zmPTyY5Qtm1wi/se/JHD5ayQv2VMOljw4B4Mc/D/E5aBQKb9zSm2M+BieV2sW/b+nN4aOWi6JFw2zmP3yxz2l4ipJoYqbcRWQY8HcgE3jdGDMmFvmc2Kiu1xSlJ6/yXhIPvmeFhMqgzrG3zpTkJzsrs0YPJpYrMRUlGmLSrxeRTOBl4FKgC3C9iHSJRV6KoiiKN7Fy2vYB1htjNhpjjgEfAFfGKC9FURTFg5jMlhGRnwLDjDG/sr//AjjPGHOXW5xRwCiAnJyccz744IOI8yspKaFhw9jvApgs1Lbygpa5tqBlDo+BAwf6nS0TK5+7r1HLGq2IMWYcMA6sqZDRTHOL5TS5ZKS2lRe0zLUFLbNzxMotUwi47zzUDtgeo7wURVEUD2Kl3OcDHUWkg4icAIwEPo9RXoqiKIoHMXHLGGMqROQuYBLWVMg3jDErYpGXoiiK4k3M5rkbY74CvopV+oqiKIp/kmJvGRHZA2yOIomWQJFD4qQCta28oGWuLWiZw+MUY4zPDfCTQrlHi4gs8DcdKB2pbeUFLXNtQcvsHCm9cZiiKIriG1XuiqIoaUi6KPdxiRYgztS28oKWubagZXaItPC5K4qiKDVJF8tdURRFcUOVu6IoShqS0spdRIaJyBoRWS8ioxMtTzSIyBsisltElruFNReRySKyzv7fzO3ag3a514jIULfwc0RkmX3tRYn2XLYYISLtRWSaiKwSkRUicq8dns5lrisi80RkqV3mx+zwtC2zCxHJFJHFIvKl/T2tyywiBbasS0RkgR0W3zIbY1LyD2tbgw3AqcAJwFKgS6LliqI8A4BewHK3sGeA0fbn0cBf7c9d7PJmAx3s55BpX5sHnI+1M+fXwKWJLpuf8rYBetmfGwFr7XKlc5kFaGh/rgPMBfqmc5ndyv4b4D3gy3Sv27asBUBLj7C4ljmVLfe0OhDEGDMd2OcRfCUw3v48HrjKLfwDY8xRY8wmYD3QR0TaAI2NMbONVTPecrsnqTDG7DDGLLI/FwOrgLakd5mNMabE/lrH/jOkcZkBRKQdMAJ43S04rcvsh7iWOZWVe1tgq9v3QjssncgxxuwASxkCrmPr/ZW9rf3ZMzypEZFcoCeWJZvWZbbdE0uA3cBkY0zalxkYCzwAuJ8wn+5lNsC3IrLQPpgI4lzmmG0cFgeCHgiSxvgre8o9ExFpCHwM3GeMORTApZgWZTbGVAI9RKQpMEFEzgoQPeXLLCKXAbuNMQtFJC+UW3yEpVSZbfobY7aLyInAZBFZHSBuTMqcypZ7bTgQZJfdNcP+v9sO91f2QvuzZ3hSIiJ1sBT7u8aYT+zgtC6zC2PMASAfGEZ6l7k/cIWIFGC5TgeJyDukd5kxxmy3/+8GJmC5keNa5lRW7rXhQJDPgZvtzzcDn7mFjxSRbBHpAHQE5tldvWIR6WuPqt/kdk9SYcv3b2CVMeZ5t0vpXOZWtsWOiNQDLgZWk8ZlNsY8aIxpZ4zJxXpHvzPG3Egal1lEGohII9dnYAiwnHiXOdGjylGOSA/HmmWxAXg40fJEWZb3gR1AOVaL/UugBTAVWGf/b+4W/2G73GtwG0EHetsVaQPwEvYq5GT7Ay7A6mL+CCyx/4aneZm7A4vtMi8H/mSHp22ZPcqfx/HZMmlbZqwZfEvtvxUu3RTvMuv2A4qiKGlIKrtlFEVRFD+oclcURUlDVLkriqKkIarcFUVR0hBV7oqiKGmIKndFUZQ0RJW7oihKGvL/AbqchOoJr3fLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_rewards(\"CartPole\", rewards, \"Continuous Q-Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: (-0.0, -0.0, -0.0, -0.0)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.2, -0.0, 0.3)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.4, -0.0, 0.6)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, -0.2, -0.0, 0.3)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.4, -0.0, 0.5)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, -0.2, 0.0, 0.3)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.4, 0.0, 0.5)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, -0.2, 0.0, 0.3)\n",
      "best_action: LEFT\n",
      "state: (-0.1, -0.4, 0.0, 0.6)\n",
      "best_action: RIGHT\n",
      "state: (-0.1, -0.2, 0.0, 0.3)\n",
      "best_action: RIGHT\n",
      "state: (-0.1, -0.0, 0.0, -0.0)\n",
      "best_action: RIGHT\n",
      "state: (-0.1, 0.2, 0.0, -0.3)\n",
      "best_action: RIGHT\n",
      "state: (-0.1, 0.4, 0.0, -0.6)\n",
      "best_action: LEFT\n",
      "state: (-0.1, 0.2, 0.0, -0.3)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.4, 0.0, -0.5)\n",
      "best_action: LEFT\n",
      "state: (-0.0, 0.2, 0.0, -0.2)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.0, 0.0, 0.1)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.2, 0.0, -0.2)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.0, 0.0, 0.1)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.2, 0.0, -0.2)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.0, -0.0, 0.1)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.2, -0.0, -0.2)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.0, -0.0, 0.1)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.2, -0.0, -0.2)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.0, -0.0, 0.1)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.2, -0.0, -0.2)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.0, -0.0, 0.0)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.2, -0.0, 0.3)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.4, -0.0, 0.6)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, -0.2, 0.0, 0.3)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.4, 0.0, 0.6)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, -0.2, 0.0, 0.3)\n",
      "best_action: LEFT\n",
      "state: (-0.1, -0.4, 0.0, 0.6)\n",
      "best_action: RIGHT\n",
      "state: (-0.1, -0.2, 0.0, 0.4)\n",
      "best_action: RIGHT\n",
      "state: (-0.1, -0.0, 0.1, 0.1)\n",
      "best_action: RIGHT\n",
      "state: (-0.1, 0.2, 0.1, -0.2)\n",
      "best_action: LEFT\n",
      "state: (-0.1, -0.0, 0.0, 0.1)\n",
      "best_action: RIGHT\n",
      "state: (-0.1, 0.2, 0.1, -0.2)\n",
      "best_action: LEFT\n",
      "state: (-0.1, -0.0, 0.0, 0.1)\n",
      "best_action: RIGHT\n",
      "state: (-0.1, 0.2, 0.1, -0.1)\n",
      "best_action: RIGHT\n",
      "state: (-0.1, 0.4, 0.0, -0.4)\n",
      "best_action: LEFT\n",
      "state: (-0.0, 0.2, 0.0, -0.1)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.4, 0.0, -0.4)\n",
      "best_action: LEFT\n",
      "state: (-0.0, 0.2, 0.0, -0.1)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.4, 0.0, -0.4)\n",
      "best_action: LEFT\n",
      "state: (-0.0, 0.2, 0.0, -0.1)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.4, 0.0, -0.3)\n",
      "best_action: LEFT\n",
      "state: (-0.0, 0.2, 0.0, -0.0)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.0, 0.0, 0.2)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.2, 0.0, -0.0)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.0, 0.0, 0.3)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.2, 0.0, 0.6)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, -0.0, 0.0, 0.3)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.2, 0.0, 0.6)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, -0.0, 0.1, 0.3)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.2, 0.1, 0.0)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.0, 0.1, 0.3)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.2, 0.1, 0.1)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.0, 0.1, 0.4)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.2, 0.1, 0.1)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.0, 0.1, 0.4)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.2, 0.1, 0.1)\n",
      "best_action: LEFT\n",
      "state: (-0.0, -0.0, 0.1, 0.5)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.2, 0.1, 0.2)\n",
      "best_action: RIGHT\n",
      "state: (-0.0, 0.4, 0.1, -0.1)\n",
      "best_action: RIGHT\n",
      "state: (0.0, 0.5, 0.1, -0.3)\n",
      "best_action: LEFT\n",
      "state: (0.0, 0.4, 0.1, -0.0)\n",
      "best_action: RIGHT\n",
      "state: (0.0, 0.5, 0.1, -0.3)\n",
      "best_action: LEFT\n",
      "state: (0.0, 0.3, 0.1, 0.0)\n",
      "best_action: RIGHT\n",
      "state: (0.0, 0.5, 0.1, -0.2)\n",
      "best_action: LEFT\n",
      "state: (0.0, 0.3, 0.1, 0.1)\n",
      "best_action: RIGHT\n",
      "state: (0.1, 0.5, 0.1, -0.2)\n",
      "best_action: LEFT\n",
      "state: (0.1, 0.3, 0.1, 0.1)\n",
      "best_action: RIGHT\n",
      "state: (0.1, 0.5, 0.1, -0.1)\n",
      "best_action: RIGHT\n",
      "state: (0.1, 0.7, 0.1, -0.4)\n",
      "best_action: LEFT\n",
      "state: (0.1, 0.5, 0.1, -0.1)\n",
      "best_action: RIGHT\n",
      "state: (0.1, 0.7, 0.1, -0.3)\n",
      "best_action: LEFT\n",
      "state: (0.1, 0.5, 0.1, -0.0)\n",
      "best_action: RIGHT\n",
      "state: (0.1, 0.7, 0.1, -0.3)\n",
      "best_action: LEFT\n",
      "state: (0.1, 0.5, 0.1, 0.0)\n",
      "best_action: RIGHT\n",
      "state: (0.2, 0.7, 0.1, -0.3)\n",
      "best_action: LEFT\n",
      "state: (0.2, 0.5, 0.1, 0.1)\n",
      "best_action: RIGHT\n",
      "state: (0.2, 0.7, 0.1, -0.2)\n",
      "best_action: RIGHT\n",
      "state: (0.2, 0.9, 0.0, -0.5)\n",
      "best_action: LEFT\n",
      "state: (0.2, 0.7, 0.0, -0.2)\n",
      "best_action: LEFT\n",
      "state: (0.2, 0.5, 0.0, 0.1)\n",
      "best_action: LEFT\n",
      "state: (0.2, 0.3, 0.0, 0.4)\n",
      "best_action: RIGHT\n",
      "state: (0.2, 0.5, 0.0, 0.1)\n",
      "best_action: LEFT\n",
      "state: (0.3, 0.3, 0.0, 0.4)\n",
      "best_action: RIGHT\n",
      "state: (0.3, 0.5, 0.1, 0.2)\n",
      "best_action: RIGHT\n",
      "state: (0.3, 0.7, 0.1, -0.1)\n",
      "best_action: RIGHT\n",
      "state: (0.3, 0.9, 0.1, -0.4)\n",
      "best_action: LEFT\n",
      "state: (0.3, 0.7, 0.1, -0.1)\n",
      "best_action: RIGHT\n",
      "state: (0.3, 0.9, 0.0, -0.3)\n",
      "best_action: RIGHT\n",
      "state: (0.3, 1.1, 0.0, -0.6)\n",
      "best_action: LEFT\n",
      "state: (0.4, 0.9, 0.0, -0.3)\n",
      "best_action: LEFT\n",
      "state: (0.4, 0.7, 0.0, -0.0)\n",
      "best_action: LEFT\n",
      "state: (0.4, 0.5, 0.0, 0.3)\n",
      "best_action: LEFT\n",
      "state: (0.4, 0.3, 0.0, 0.6)\n",
      "best_action: LEFT\n",
      "state: (0.4, 0.1, 0.0, 0.9)\n",
      "best_action: RIGHT\n",
      "state: (0.4, 0.3, 0.1, 0.6)\n",
      "best_action: RIGHT\n",
      "state: (0.4, 0.5, 0.1, 0.3)\n",
      "best_action: LEFT\n",
      "state: (0.4, 0.3, 0.1, 0.7)\n",
      "best_action: RIGHT\n",
      "state: (0.4, 0.5, 0.1, 0.4)\n",
      "best_action: RIGHT\n",
      "state: (0.4, 0.7, 0.1, 0.1)\n",
      "best_action: LEFT\n",
      "state: (0.5, 0.5, 0.1, 0.4)\n",
      "best_action: RIGHT\n",
      "state: (0.5, 0.7, 0.1, 0.2)\n",
      "best_action: LEFT\n",
      "state: (0.5, 0.5, 0.1, 0.5)\n",
      "best_action: LEFT\n",
      "state: (0.5, 0.3, 0.1, 0.8)\n",
      "best_action: RIGHT\n",
      "state: (0.5, 0.5, 0.1, 0.6)\n",
      "best_action: LEFT\n",
      "state: (0.5, 0.3, 0.2, 0.9)\n",
      "best_action: LEFT\n",
      "state: (0.5, 0.1, 0.2, 1.3)\n",
      "best_action: RIGHT\n",
      "state: (0.5, 0.3, 0.2, 1.0)\n",
      "best_action: RIGHT\n",
      "Terminal state reached.\n",
      "State: (0.5, 0.5, 0.2, 0.8)\n"
     ]
    }
   ],
   "source": [
    "def fn():\n",
    "    action_dict = {\n",
    "        0: \"LEFT\",\n",
    "        1: \"RIGHT\"\n",
    "    }\n",
    "    state, _ = env.reset()\n",
    "    print(f\"state: {state}\")\n",
    "    while True:\n",
    "        best_action = agent.max_action(state)\n",
    "        print(f\"best_action: {action_dict[best_action]}\")\n",
    "        next_state, reward, done, trunc, _ = env.step(best_action)\n",
    "        if done or trunc:\n",
    "            print(f\"Terminal state reached.\\nState: {next_state}\")\n",
    "            break\n",
    "        state = next_state\n",
    "        print(f\"state: {state}\")\n",
    "\n",
    "fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
