{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b60c823",
   "metadata": {},
   "source": [
    "References:\n",
    "- https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_gnn.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75abbad9",
   "metadata": {},
   "source": [
    "## Message Passing Framework\n",
    "\n",
    "Generalizing the convolution operator to irregular domains is typically expressed as a neighborhood aggregation or message passing scheme. With $\\mathbf{x}^{(k-1)}_i \\in \\mathbb{R}^F$ denoting node features of node $i$ in layer $(k-1)$ and $\\mathbf{e}_{j,i} \\in \\mathbb{R}^D$ denoting (optional) edge features from node $j$ to node $i$, message passing graph neural networks can be described as:\n",
    "\n",
    "$$\\mathbf{x}_i^{(k)} = \\gamma^{(k)} \\left( \\mathbf{x}_i^{(k-1)}, \\bigoplus_{j \\in \\mathcal{N}(i)} \\, \\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)},\\mathbf{e}_{j,i}\\right) \\right)$$\n",
    "\n",
    "where:\n",
    "- $\\bigoplus$ denotes the aggregation function which is a differentiable, permutation invariant function, e.g., sum, mean or max.\n",
    "- $\\gamma$ denotes the update function which is a differentiable function, e.g., MLP (Multi Layer Perceptrons).\n",
    "- $\\phi$ denotes the message function which is a differentiable function, e.g., MLP (Multi Layer Perceptrons)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd79ea52",
   "metadata": {},
   "source": [
    "- Permutation invariance = The output does not change if the input is permuted. In the context of graph neural networks, this means that function does not depend on the arbitrary ordering of the rows/columns in the adjacency matrix.\n",
    "- Permutation equivariance = The output changes in the same way as the input when the input is permuted. In graph neural networks, this means that the function is permuted in a consistent way when we permute the adjacency matrix.\n",
    "\n",
    "\n",
    "Ensuring invariance or equivariance is a key challenge when we are learning over graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d541988",
   "metadata": {},
   "source": [
    "### Implementing the GCN Layer\n",
    "\n",
    "The [GCN layer](https://arxiv.org/abs/1609.02907) is mathematically defined as:\n",
    "\n",
    "$$\\mathbf{x}_i^{(k)} = \\sum_{j \\in \\mathcal{N}(i) \\cup \\{ i \\}} \\frac{1}{\\sqrt{\\deg(i)} \\cdot \\sqrt{\\deg(j)}} \\cdot \\left( \\mathbf{W}^{\\top} \\cdot \\mathbf{x}_j^{(k-1)} \\right) + \\mathbf{b}$$\n",
    "\n",
    "where neighboring node features are first transformed by a weight matrix $\\mathbf{W}$, normalized by their degree, and finally summed up. Lastly, we apply the bias vector $\\mathbf{b}$ to the aggregated output. This formula can be divided into the following steps:\n",
    "\n",
    "1. Add self-loops to the adjacency matrix.\n",
    "2. Linearly transform node feature matrix.\n",
    "3. Compute normalization coefficients.\n",
    "4. Normalize node features in $\\phi$.\n",
    "5. Sum up neighboring node features (\"add\" aggregation).\n",
    "6. Apply a final bias vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7685a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports done\n",
      "torch version: 2.6.0+cpu\n",
      "torch_geometric version: 2.5.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "print(\"imports done\")\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"torch_geometric version:\", torch_geometric.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36577125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(pyg_nn.MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__(aggr='add')\n",
    "        self.lin = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = nn.Parameter(torch.empty(out_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = pyg_utils.add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = pyg_utils.degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        # self.propagate() internally calls message(), aggregate() and update() methods.\n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "        # Step 6: Apply a final bias vector.\n",
    "        out = out + self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0babd62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8987276c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3c65c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
